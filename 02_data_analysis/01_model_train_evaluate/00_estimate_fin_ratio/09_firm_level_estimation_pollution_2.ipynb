{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Model estimate Estimate internal finance and pollution emission firm level\n",
    "\n",
    "# Description\n",
    "None\n",
    "# Metadata\n",
    "- Key: 488_Financial_dependency_pollution\n",
    "- Epic: Models\n",
    "- US: Evaluate econometrics model\n",
    "- Task tag: #internal-finance, #training-Financial-dependency-pollution\n",
    "- Analytics reports: \n",
    "# Input\n",
    "## Table/file\n",
    "**Name**\n",
    "- asif_financial_ratio_baseline_firm\n",
    "- china_firm_pollution_data\n",
    "**Github**\n",
    "- https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/02_data_analysis/01_model_train_evaluate/00_estimate_fin_ratio/08_firm_level_estimation_pollution.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'rootkey.csv'\n",
    "region = 'eu-west-2'\n",
    "bucket = 'datalake-london'\n",
    "path_cred = \"creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types\n",
    "\n",
    "- 1=state -> 110 141 143 151\n",
    "- 2=collective -> 120 130 142 149\n",
    "- 3=private -171 172 173 174 190\n",
    "- 4=foreign- 210 220 230 240\n",
    "- 5=Hong Kong, Macau and Taiwan (4 and 5 can be combined into a single \"foreign\" category - 310 320 330 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'environment'\n",
    "table = 'firm_financial_ratio_from_pollution1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = True\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalog/temporary_local_data\")\n",
    "df_path = 'df_asif.csv'#os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def construct_table(table=\"firm_financial_ratio_from_pollution1\"):\n",
    "    query = f\"\"\"\n",
    "WITH temp as (\n",
    "  SELECT \n",
    "    \"firm\", \n",
    "    \"year\", \n",
    "    geocode4_corr, \n",
    "    province_en, \n",
    "    \"cic_adj\", \n",
    "    \"cic03\", \n",
    "    \"ownership_new\", \n",
    "    \"total_industrialwater_used\", \n",
    "    \"total_freshwater_used\", \n",
    "    \"gyqs\", \n",
    "    \"total_repeatedwater_used\", \n",
    "    \"total_coal_used\", \n",
    "    \"rlmxf\", \n",
    "    \"ylmxf\", \n",
    "    \"rlmpjlf\", \n",
    "    \"rlyxf\", \n",
    "    \"zyxf\", \n",
    "    \"cyxf\", \n",
    "    \"rlypjlf\", \n",
    "    \"zypjlf\", \n",
    "    \"clean_gas_used\", \n",
    "    \"waste_water\", \n",
    "    \"cod\", \n",
    "    \"ad\", \n",
    "    \"waste_gas\", \n",
    "    \"so2\", \n",
    "    \"nox\", \n",
    "    \"smoke_dust\", \n",
    "    \"soot\", \n",
    "    \"yfc\", \n",
    "    \"gyfscll\", \n",
    "    \"hxxyqcl\", \n",
    "    \"xzssqcl\", \n",
    "    \"adqcl\", \n",
    "    \"eyhlqcl\", \n",
    "    \"dyhwqcl\", \n",
    "    \"ycqcl\", \n",
    "    \"gyfcqcl\", \n",
    "    \"dwastewater_equip\", \n",
    "    \"fszlssnl\", \n",
    "    \"fszlssfee\", \n",
    "    \"dwastegas_equip\", \n",
    "    \"dso2_equip\", \n",
    "    \"fqzlssnl\", \n",
    "    \"tlssnl\", \n",
    "    \"hxxycsl\", \n",
    "    \"adcsl\", \n",
    "    \"eyhlcsl\", \n",
    "    \"dyhwcsl\", \n",
    "    \"yfccsl\", \n",
    "    \"age\", \n",
    "    \"bdat\", \n",
    "    \"export\",\n",
    "    c125,\n",
    "    c133,\n",
    "    c98,\n",
    "    CASE \n",
    "    WHEN c98 <> 0 THEN CAST(c125 AS DOUBLE) / c98\n",
    "    ELSE NULL\n",
    "END AS interest_expense,\n",
    "CASE\n",
    "    WHEN c98 <> 0 THEN CAST(c133 AS DOUBLE) / c98\n",
    "    ELSE NULL\n",
    "END AS interest_expense1\n",
    "\n",
    "    \n",
    "  FROM \n",
    "    \"environment\".\"china_firm_pollution_data\" \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr, \n",
    "        province_en \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised \n",
    "      GROUP BY \n",
    "        extra_code, \n",
    "        province_en, \n",
    "        geocode4_corr\n",
    "    ) as no_dup_citycode ON china_firm_pollution_data.citycode = no_dup_citycode.extra_code\n",
    ") \n",
    "SELECT \n",
    "  temp.firm, \n",
    "  temp.year, \n",
    "  temp.geocode4_corr, \n",
    "  tcz, \n",
    "  spz, \n",
    "  temp.province_en, \n",
    "  temp.cic_adj, \n",
    "  temp.cic03, \n",
    "  indu_2,\n",
    "  temp.ownership_new, \n",
    "  \"output\", \n",
    "  \"outputdefl\", \n",
    "  \"sales\", \n",
    "  \"employment\", \n",
    "  \"capital\", \n",
    "  \"total_industrialwater_used\", \n",
    "  \"total_freshwater_used\", \n",
    "  \"gyqs\", \n",
    "  \"total_repeatedwater_used\", \n",
    "  \"total_coal_used\", \n",
    "  \"rlmxf\", \n",
    "  \"ylmxf\", \n",
    "  \"rlmpjlf\", \n",
    "  \"rlyxf\", \n",
    "  \"zyxf\", \n",
    "  \"cyxf\", \n",
    "  \"rlypjlf\", \n",
    "  \"zypjlf\", \n",
    "  \"clean_gas_used\", \n",
    "  \"waste_water\", \n",
    "  \"cod\", \n",
    "  \"ad\", \n",
    "  \"waste_gas\", \n",
    "  \"so2\", \n",
    "  \"nox\", \n",
    "  \"smoke_dust\", \n",
    "  \"soot\", \n",
    "  \"yfc\", \n",
    "  \"gyfscll\", \n",
    "  \"hxxyqcl\", \n",
    "  \"xzssqcl\", \n",
    "  \"adqcl\", \n",
    "  \"eyhlqcl\", \n",
    "  \"dyhwqcl\", \n",
    "  \"ycqcl\", \n",
    "  \"gyfcqcl\", \n",
    "  \"dwastewater_equip\", \n",
    "  \"fszlssnl\", \n",
    "  \"fszlssfee\", \n",
    "  \"dwastegas_equip\", \n",
    "  \"dso2_equip\", \n",
    "  \"fqzlssnl\", \n",
    "  \"tlssnl\", \n",
    "  \"hxxycsl\", \n",
    "  \"adcsl\", \n",
    "  \"eyhlcsl\", \n",
    "  \"dyhwcsl\", \n",
    "  \"yfccsl\", \n",
    "  \"age\", \n",
    "  \"bdat\", \n",
    "  \"export\", \n",
    "  \"tfp_op\", \n",
    "  \"tfp_lp\",\n",
    "  CASE WHEN rd_tot_asset IS NULL THEN -1000 WHEN rd_tot_asset < 0 THEN 0 ELSE rd_tot_asset END AS rd_tot_asset_trick, \n",
    "  CASE WHEN temp.ownership_new in (1.0) THEN 'SOE' ELSE 'NOT_SOE' END AS SOE, \n",
    "  CASE WHEN temp.ownership_new in (4.0, 5.0) THEN 'FOREIGN' ELSE 'NOT_FOREIGN' END AS FOREIGN, \n",
    "  \"current_asset\", \n",
    "  \"tofixed\", \n",
    "  \"total_liabilities\", \n",
    "  \"tangible\", \n",
    "  \"net_non_current\", \n",
    "  \"cashflow\", \n",
    "  \"working_capital\", \n",
    "  \"current_ratio\", \n",
    "  \"quick_ratio\", \n",
    "  \"liabilities_tot_asset\", \n",
    "  \"sales_tot_asset\", \n",
    "  \"total_asset\", \n",
    "  \"investment_tot_asset\", \n",
    "  \"rd_tot_asset\", \n",
    "  \"asset_tangibility_tot_asset\", \n",
    "  \"cashflow_tot_asset\", \n",
    "  \"cashflow_to_tangible\", \n",
    "  \"return_to_sale\", \n",
    "  \"coverage_ratio\", \n",
    "  \"working_capital_ratio\", \n",
    "  \"roa\", \n",
    "  \"roe\", \n",
    "  \"ros\", \n",
    "  \"liquidity\", \n",
    "  \"current_asset_tot_asset\", \n",
    "  \"tangible_tot_asset\", \n",
    "  \"net_non_current_tot_asset\", \n",
    "  \"working_capital_tot_asset\", \n",
    "  \"current_ratio_tot_asset\", \n",
    "  \"quick_ratio_tot_asset\", \n",
    "  concat(indu_2, '-', temp.year) as fe_indu2_year, \n",
    "  concat(\n",
    "    temp.geocode4_corr, '-', temp.year\n",
    "  ) as fe_city_year ,\n",
    "  interest_expense,\n",
    "  interest_expense1,\n",
    "  c125,\n",
    "  c133,\n",
    "  c98\n",
    "FROM \n",
    "  temp \n",
    "  INNER JOIN \"environment\".\"{table}\" ON temp.firm = {table}.firm \n",
    "  AND temp.year = {table}.year \n",
    "  AND temp.geocode4_corr = {table}.geocode4_corr \n",
    "  AND temp.province_en = {table}.province_en \n",
    "  AND temp.cic_adj = {table}.cic_adj \n",
    "  AND temp.cic03 = {table}.cic03 \n",
    "  AND temp.ownership_new = {table}.ownership_new \n",
    "  LEFT JOIN policy.china_city_tcz_spz ON temp.geocode4_corr = china_city_tcz_spz.geocode4_corr \n",
    "  INNER JOIN (\n",
    "    SELECT \n",
    "      \"firm\", \n",
    "      \"year\", \n",
    "      \"citycode_asifad\" as geocode4_corr, \n",
    "      \"tfp_op\", \n",
    "      \"tfp_lp\" \n",
    "    FROM \n",
    "      firms_survey.firm_tfp_china\n",
    "  ) as tfp_table on temp.firm = tfp_table.firm \n",
    "  and temp.geocode4_corr = tfp_table.geocode4_corr \n",
    "  and temp.year = tfp_table.year \n",
    "ORDER BY \n",
    "  firm, \n",
    "  year\n",
    "    \"\"\"\n",
    "    df = s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=filename,  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "        dtype=dtypes,\n",
    "    ).assign(\n",
    "        #tcz=lambda x: x[\"tcz\"].fillna(0).astype(\"int\").astype(\"str\"),\n",
    "        spz=lambda x: x[\"spz\"].fillna(0).astype(\"int\").astype(\"str\"),\n",
    "        fe_fo=lambda x: le.fit_transform(x[\"firm\"].astype(\"str\")),\n",
    "        fe_indu2_year=lambda x: le.fit_transform(x[\"fe_indu2_year\"].astype(\"str\")),\n",
    "        fe_city_year=lambda x: le.fit_transform(x[\"fe_city_year\"].astype(\"str\")),\n",
    "    )\n",
    "    query = \"\"\"\n",
    "SELECT * FROM \"industry\".\"china_credit_constraint\"\n",
    "\"\"\"\n",
    "    df_credit = s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=filename,  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "        dtype=dtypes,\n",
    "    )\n",
    "    df = df.merge(df_credit.rename(columns={\"cic\": \"indu_2\"}), how=\"left\").assign(\n",
    "        financial_dep_china1 = lambda x: -x['financial_dep_china'],\n",
    "        constraint=lambda x: x[\"financial_dep_china\"] < -0.44,\n",
    "        constraint_1=lambda x: x[\"financial_dep_china\"] < -0.26,\n",
    "    )\n",
    "    df_final = df.assign(\n",
    "        **{\n",
    "            f\"lag_{c}\": df.groupby([\"firm\"])[c].transform(\"shift\")\n",
    "            for c in [\n",
    "                \"sales\",\n",
    "                \"tfp_op\",\n",
    "                \"tfp_lp\",\n",
    "                \"cashflow\", \n",
    "                  \"working_capital\", \n",
    "                  \"current_ratio\", \n",
    "                  \"quick_ratio\", \n",
    "                  \"liabilities_tot_asset\", \n",
    "                  \"sales_tot_asset\", \n",
    "                  \"total_asset\", \n",
    "                  \"investment_tot_asset\", \n",
    "                  \"rd_tot_asset\", \n",
    "                  \"asset_tangibility_tot_asset\", \n",
    "                  \"cashflow_tot_asset\", \n",
    "                  \"cashflow_to_tangible\", \n",
    "                  \"return_to_sale\", \n",
    "                  \"coverage_ratio\", \n",
    "                  \"working_capital_ratio\", \n",
    "                  \"roa\", \n",
    "                  \"roe\", \n",
    "                  \"ros\", \n",
    "                  \"liquidity\", \n",
    "                  \"current_asset_tot_asset\", \n",
    "                  \"tangible_tot_asset\", \n",
    "                  \"net_non_current_tot_asset\", \n",
    "                  \"working_capital_tot_asset\", \n",
    "                  \"current_ratio_tot_asset\", \n",
    "                  \"quick_ratio_tot_asset\"\n",
    "            ]\n",
    "        }\n",
    "    ).sort_values(by = ['firm','year'])\n",
    "    #.dropna(\n",
    "     #   subset=[\n",
    "     #       \"lag_cashflow_to_tangible\",\n",
    "     #       \"lag_sales_tot_asset\",\n",
    "     #       \"lag_liabilities_tot_asset\",\n",
    "     #   ]\n",
    "    #)\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query_mandate = \"\"\"\n",
    "SELECT geocode4_corr,\"tso2_mandate_c\", \"so2_perc_reduction_c\", \"target_reduction_so2_p\"\n",
    "FROM \"policy\".\"china_city_reduction_mandate\"\n",
    "INNER JOIN (\n",
    "      SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr, \n",
    "        cityen\n",
    " \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised \n",
    "      GROUP BY \n",
    "        extra_code, \n",
    "        cityen, \n",
    "        geocode4_corr\n",
    "    ) as no_dup_citycode ON china_city_reduction_mandate.cityen = no_dup_citycode.cityen\n",
    "\"\"\"\n",
    "df_mandate = (\n",
    "    s3.run_query(\n",
    "        query=query_mandate,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=filename,  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "    )\n",
    "    .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_mandate.to_csv('mandate.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH temp AS (\n",
    "SELECT year, no_dup_citycode.geocode4_corr,indus_code as cic_adj, \n",
    "substr(indus_code, 1,2) as ind2,\n",
    "innovation_index\n",
    "FROM innovation_city_industry\n",
    "INNER JOIN (\n",
    "    SELECT \n",
    "      extra_code, \n",
    "      geocode4_corr \n",
    "    FROM \n",
    "      chinese_lookup.china_city_code_normalised \n",
    "    GROUP BY \n",
    "      extra_code, \n",
    "      geocode4_corr\n",
    "  ) as no_dup_citycode ON innovation_city_industry.geocode4_corr = no_dup_citycode.extra_code\n",
    "  )\n",
    "  SELECT year, geocode4_corr, \n",
    "  cic_adj,\n",
    "  ind2,\n",
    "  AVG(innovation_index) as innovation_index,\n",
    "  MAX(innovation_index) as innovation_index_1,\n",
    "  approx_percentile(innovation_index, ARRAY[0.50])[1] as innovation_index_2\n",
    "  FROM temp\n",
    "  GROUP BY year, geocode4_corr,\n",
    "  cic_adj,\n",
    "  ind2\n",
    "\"\"\"\n",
    "df_innovation = (s3.run_query(\n",
    "            query=query,\n",
    "            database=\"china\",\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "df_innovation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "df_innovation.to_csv('df_innovation.csv', index = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_innovation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      province_loan_and_credit.year, \n",
    "      province_loan_and_credit.province_en, \n",
    "      CAST(\n",
    "        total_long_term_loan AS DECIMAL(16, 5)\n",
    "      )/ CAST(\n",
    "        total_gdp AS DECIMAL(16, 5)\n",
    "      ) AS credit_supply_long_term, \n",
    "      CAST(\n",
    "        total_short_term AS DECIMAL(16, 5)\n",
    "      )/ CAST(\n",
    "        total_gdp AS DECIMAL(16, 5)\n",
    "      ) AS credit_supply_short_term \n",
    "    FROM \n",
    "      almanac_bank_china.province_loan_and_credit\n",
    "\"\"\"\n",
    "df_credit_supply = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "df_credit_supply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_company_registration_type(x):\n",
    "    regex = r'有限公司|信用合作联社|有限责任公司|旧市支行|族自治州分行|县支行|市支行|村支行|市分行|农村合作银行|自治区分行|支行|合作社联合社'\\\n",
    "'|分行|资金互助社|信用社联合社|股份公司|住宅金融事业部|国家开发银行|总行营业部|合作金融结算服务中心|信用合作社|信托投资公司'\n",
    "    matches = re.findall(regex,x)\n",
    "    if len(matches) > 0:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return np.nan \n",
    "def get_type(x):\n",
    "    if re.search(r\"中国工商银行|中国建设银行|中国银行|中国农业银行|交通银行|中国邮政储蓄银行\", str(x)):\n",
    "        return (re.search(r\"中国工商银行|中国建设银行|中国银行|中国农业银行|交通银行|中国邮政储蓄银行\", \n",
    "                          str(x)).group(), \"SOB\")\n",
    "    elif re.search(r\"中国农业发展银行|国家开发银行|中国进出口银行\", str(x)):\n",
    "        return (re.search(r\"中国农业发展银行|国家开发银行|中国进出口银行\", str(x)).group(),\n",
    "                \"policy bank\")\n",
    "    elif re.search(r\"股份制商业银行\", str(x)):\n",
    "        return (re.search(r\"股份制商业银行|银行股份\", str(x)).group(), \"joint-stock commercial bank\")\n",
    "    #elif re.search(r\"城市商业银行\", str(x)):\n",
    "    #    return (re.search(r\"城市商业银行\", str(x)).group(), \"city commercial bank\")\n",
    "    elif re.search(r\"农村商业银行\", str(x)):\n",
    "        return (re.search(r\"农村商业银行\", str(x)).group(), \"rural commercial bank\")\n",
    "    elif re.search(r\"外资银行\", str(x)):\n",
    "        return (re.search(r\"外资银行\", str(x)).group(), \"foreign bank\")\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM china.branches_raw_csv\n",
    "\"\"\"\n",
    "df_bank = (\n",
    "    s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=\"bank\",  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "        dtype = {'id':'str','geocode4_corr':'str', 'lostReason':'str',\n",
    "                       'location':'str', 'city_temp':'str', 'points':'str'}\n",
    "    )\n",
    "    .assign(\n",
    "        setdate=lambda x: pd.to_datetime(x[\"setdate\"].astype(\"Int64\").astype(str), errors ='coerce'),\n",
    "        printdate=lambda x: pd.to_datetime(x[\"printdate\"].astype(\"Int64\").astype(str), errors ='coerce'),\n",
    "        year_setdate=lambda x: x[\"setdate\"].dt.year.astype(\"Int64\").astype(str),\n",
    "        bank_temp=lambda x: x.apply(\n",
    "            lambda x: get_company_registration_type(x[\"fullname\"]), axis=1\n",
    "        ),\n",
    "        geocode4_corr = lambda x: x['geocode4_corr'].astype(\"Int64\").astype(str)\n",
    "    )\n",
    "     .assign(\n",
    "         registration_type=lambda x: x.apply(\n",
    "            lambda x: np.nan if pd.isna(x[\"bank_temp\"]) else x[\"bank_temp\"], axis=1\n",
    "        ),\n",
    "        bank_full_name=lambda x: x.apply(\n",
    "            lambda x: x[\"fullname\"]\n",
    "            if pd.isna(x[\"bank_temp\"])\n",
    "            else x[\"fullname\"].split(x[\"registration_type\"][0])[0],\n",
    "            axis=1,\n",
    "        ),\n",
    "        list_bank_type=lambda x: x.apply(lambda x: get_type(x[\"bank_full_name\"]), axis=1),\n",
    "        bank_type=lambda x: x.apply(\n",
    "            lambda x: np.nan if pd.isna(x[\"list_bank_type\"]) else x[\"list_bank_type\"][0], axis=1\n",
    "        ),\n",
    "        bank_type_adj=lambda x: x.apply(\n",
    "            lambda x: np.nan if pd.isna(x[\"list_bank_type\"]) else x[\"list_bank_type\"][1], axis=1\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        bank_type_1 = lambda x: x['certcode'].str.slice(stop = 1),\n",
    "        bank_code = lambda x: x['certcode'].str.slice(stop = 7),\n",
    "        bank_type_details = lambda x: x['certcode'].str.slice(start = 5, stop = 6),\n",
    "        citycode = lambda x: x['certcode'].str.slice(start = 7, stop = 11),\n",
    "        unknown_code = lambda x: x['certcode'].str.slice(start = 11),\n",
    "    )\n",
    "    .drop(columns=[\"bank_temp\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM china.china_bank_information\n",
    "\"\"\"\n",
    "df_bank_info = (\n",
    "    s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=\"bank\",  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "        dtype=dtypes,\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"shortbnm\"])\n",
    "    .replace(\n",
    "        {\n",
    "            \"bnature\": {\n",
    "                1: \"政策性银行\",\n",
    "                2: \"国有控股大型商业银行\",\n",
    "                3: \"股份制商业银行\",\n",
    "                4: \"城市商业银行\",\n",
    "                5: \"农村商业银行\",\n",
    "                6: \"外资银行\",\n",
    "                7: \"其他\",\n",
    "                8: \"农合行\",\n",
    "                9: \"农信社\",\n",
    "                10: \"三类新型农村金融机构\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_bank_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "### CCB\n",
    "temp_city_branch = (\n",
    "    df_bank.loc[lambda x: x[\"bank_type_adj\"].isin([np.nan])]\n",
    "    .loc[lambda x: x[\"bank_type_details\"].isin([\"S\"])]\n",
    "    .loc[lambda x: x[\"bank_type_1\"].isin([\"B\", \"L\"])]\n",
    "    .loc[lambda x: ~x[\"fullname\"].str.contains(\"村镇\")]\n",
    "    .assign(bank_type=\"城市商业银行\", status=\"CCB\")\n",
    "    .reindex(\n",
    "        columns=[\n",
    "            \"id\",\n",
    "            \"certcode\",\n",
    "            \"bank_type_adj\",\n",
    "            \"bank_type_1\",\n",
    "            \"bank_type\",\n",
    "            \"bank_type_details\",\n",
    "            \"unknown_code\",\n",
    "            \"fullname\",\n",
    "            \"registration_type\",\n",
    "            \"bank_full_name\",\n",
    "            \"citycode\",\n",
    "            'geocode4_corr',\n",
    "            \"bank_code\",\n",
    "            \"year_setdate\",\n",
    "            \"status\",\n",
    "        ]\n",
    "    )\n",
    "    .rename(columns={\n",
    "        #\"citycode\": \"geocode4_corr\",\n",
    "        \"year_setdate\": \"year\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#### no city bank\n",
    "df_bank_concat = (\n",
    "    pd.concat(\n",
    "    [\n",
    "        (\n",
    "            df_bank.loc[lambda x: ~x[\"bank_type_adj\"].isin([np.nan])]\n",
    "            .loc[lambda x: x[\"bank_type_details\"].isin([\"S\"])]\n",
    "            .reindex(\n",
    "                columns=[\n",
    "                    \"id\",\n",
    "                    \"certcode\",\n",
    "                    \"bank_type_adj\",\n",
    "                    \"bank_type_1\",\n",
    "                    \"bank_type\",\n",
    "                    \"bank_type_details\",\n",
    "                    \"unknown_code\",\n",
    "                    \"fullname\",\n",
    "                    \"registration_type\",\n",
    "                    \"bank_full_name\",\n",
    "                    \"citycode\",\n",
    "                    \"bank_code\",\n",
    "                    \"year_setdate\",\n",
    "                ]\n",
    "            )\n",
    "            .assign(status=\"no CCB\",)\n",
    "        ),\n",
    "        ### rural\n",
    "        (\n",
    "            df_bank.loc[lambda x: x[\"bank_type_adj\"].isin([np.nan])]\n",
    "            .loc[lambda x: x[\"bank_type_details\"].isin([\"S\"])]\n",
    "            .loc[lambda x: x['fullname'].str.contains('村镇')]\n",
    "            .assign(bank_type=\"农村商业银行\", status=\"no CCB\")\n",
    "            .reindex(\n",
    "                columns=[\n",
    "                    \"id\",\n",
    "                    \"certcode\",\n",
    "                    \"bank_type_adj\",\n",
    "                    \"bank_type_1\",\n",
    "                    \"bank_type\",\n",
    "                    \"bank_type_details\",\n",
    "                    \"unknown_code\",\n",
    "                    \"fullname\",\n",
    "                    \"registration_type\",\n",
    "                    \"bank_full_name\",\n",
    "                    \"citycode\",\n",
    "                    \"geocode4_corr\",\n",
    "                    \"bank_code\",\n",
    "                    \"year_setdate\",\n",
    "                    \"status\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "    .rename(\n",
    "    columns = {\n",
    "        #'citycode':'geocode4_corr',\n",
    "        'year_setdate':'year'\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from polyfuzz.models import RapidFuzz\n",
    "from polyfuzz import PolyFuzz\n",
    "rapidfuzz_matcher = RapidFuzz(n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "banks_no_ccb = (\n",
    "    [ i.replace('（中国）','').strip() for i in \n",
    "     (\n",
    "    df_bank_concat['bank_full_name'].dropna().drop_duplicates().to_list()\n",
    ")\n",
    "     if len(i) > 1]\n",
    ")\n",
    "bank_info = df_bank_info.loc[lambda x: ~x['bnature'].isin(['城市商业银行'])]['shortbnm'].to_list()\n",
    "no_ccb = PolyFuzz(rapidfuzz_matcher).match(banks_no_ccb, bank_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "banks = (\n",
    "    [ i.replace('（中国）','').strip() for i in \n",
    "     (\n",
    "    temp_city_branch['bank_full_name'].dropna().drop_duplicates().to_list()\n",
    ")\n",
    "     if len(i) > 1]\n",
    ")\n",
    "bank_info = df_bank_info.loc[lambda x: x['bnature'].isin(['城市商业银行'])]['shortbnm'].to_list()\n",
    "model = PolyFuzz(rapidfuzz_matcher).match(banks, bank_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr, \n",
    "        province_en \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised\n",
    "\"\"\"\n",
    "df_citycode = (s3.run_query(\n",
    "            query=query,\n",
    "            database=\"china\",\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "df_citycode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank_status = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            (\n",
    "                df_bank_concat.merge(\n",
    "                    no_ccb.get_matches()\n",
    "                    .sort_values(by=[\"Similarity\"])\n",
    "                    .loc[lambda x: x[\"Similarity\"] > 0.80]\n",
    "                    .rename(columns={\"From\": \"bank_full_name\"})\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                temp_city_branch.merge(\n",
    "                    model.get_matches()\n",
    "                    .sort_values(by=[\"Similarity\"])\n",
    "                    .loc[lambda x: x[\"Similarity\"] > 0.80]\n",
    "                    .rename(columns={\"From\": \"bank_full_name\"})\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    .rename(columns={\"To\": \"bank_name\"})\n",
    "    .assign(\n",
    "        geocode4_corr=lambda x: np.where(\n",
    "            x[\"geocode4_corr\"].isin([\"<NA>\", np.nan]), x[\"citycode\"], x[\"geocode4_corr\"]\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        bank_type_adj=lambda x: np.where(\n",
    "            np.logical_and(\n",
    "                x[\"bank_type_adj\"].isin([np.nan]), x[\"bank_type\"] == \"农村商业银行\"\n",
    "            ),\n",
    "            \"rural commercial bank\",\n",
    "            x[\"bank_type_adj\"],\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        bank_type_adj=lambda x: np.where(\n",
    "            np.logical_and(\n",
    "                x[\"bank_type_adj\"].isin([np.nan]), x[\"bank_type\"] == \"城市商业银行\"\n",
    "            ),\n",
    "            \"city commercial bank\",\n",
    "            x[\"bank_type_adj\"],\n",
    "        )\n",
    "    )\n",
    "    .merge(\n",
    "        df_citycode.drop_duplicates()\n",
    "        .assign(extra_code=lambda x: x[\"extra_code\"].astype(str))\n",
    "        .rename(columns={\"geocode4_corr\": \"geocode4_corr_adj\"}),\n",
    "        right_on=[\"extra_code\"],\n",
    "        left_on=[\"geocode4_corr\"],\n",
    "    )\n",
    "    .drop(columns = ['geocode4_corr','extra_code'])\n",
    "    .rename(columns={\"geocode4_corr_adj\": \"geocode4_corr\"})\n",
    ")\n",
    "df_bank_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_ccb = (\n",
    "    #### Number of CCB per city\n",
    "    df_bank_status.pivot_table(\n",
    "        values=\"id\",\n",
    "        index=[\"status\", \"bank_name\", \"geocode4_corr\"],\n",
    "        columns=\"year\",\n",
    "        aggfunc=\"nunique\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"count\"})\n",
    "    .assign(\n",
    "        count=lambda x: x.groupby([\"status\", \"bank_name\", \"geocode4_corr\"])[\n",
    "            \"count\"\n",
    "        ].transform(\"cumsum\"),\n",
    "        active=lambda x: np.where(x[\"count\"] > 0, 1, 0),\n",
    "    )\n",
    "    .groupby([\"year\", \"geocode4_corr\", \"status\"])\n",
    "    .agg({\"count\": \"sum\", \"active\": \"sum\"})\n",
    "    .unstack(-1)\n",
    "    .collapse_levels(sep=\"_\")\n",
    "    .rename(columns={\"count_no CCB\": \"count_no_CCB\", \"active_no CCB\": \"active_no_CCB\",})\n",
    "    .fillna(0)\n",
    "    .assign(\n",
    "        share_count_ccb=lambda x: (x[\"count_CCB\"] / (x[\"count_CCB\"] + x[\"count_no_CCB\"])),\n",
    "        share_active_ccb=lambda x: (x[\"active_CCB\"] / (x[\"active_CCB\"] + x[\"active_no_CCB\"])),\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "df_ccb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_hhi = (\n",
    "            #### HHI\n",
    "            df_bank_status.pivot_table(\n",
    "                values=\"id\",\n",
    "                index=[\"bank_name\", \"geocode4_corr\"],\n",
    "                columns=\"year\",\n",
    "                aggfunc=\"nunique\",\n",
    "                fill_value=0,\n",
    "            )\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"count\"})\n",
    "            .assign(\n",
    "                count=lambda x: x.groupby([\"bank_name\", \"geocode4_corr\"])[\n",
    "                    \"count\"\n",
    "                ].transform(\"cumsum\"),\n",
    "                active=lambda x: np.where(x[\"count\"] > 0, 1, 0),\n",
    "                total_city=lambda x: x.groupby([\"year\", \"geocode4_corr\"])[\n",
    "                    \"count\"\n",
    "                ].transform(\"sum\"),\n",
    "                total_city_active=lambda x: x.groupby([\"year\", \"geocode4_corr\"])[\n",
    "                    \"active\"\n",
    "                ].transform(\"sum\"),\n",
    "                score_count=lambda x: (x[\"count\"] / x[\"total_city\"]) ** 2,\n",
    "                score_active=lambda x: (x[\"active\"] / x[\"total_city_active\"]) ** 2,\n",
    "            )\n",
    "            .groupby([\"year\", \"geocode4_corr\"])\n",
    "            .agg({\"score_count\": \"sum\", \"score_active\": \"sum\"})\n",
    "            .assign(\n",
    "                hhi_branches=lambda x: 1 - x[\"score_count\"],\n",
    "                hhi_branches_name=lambda x: 1 - x[\"score_active\"],\n",
    "            )\n",
    "        )\n",
    "df_hhi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def big_four(x):\n",
    "    if x == \"中国农业银行股份\":\n",
    "        return \"中国农业银行股份\"\n",
    "    elif x == \"中国工商银行股份\":\n",
    "        return \"中国工商银行股份\"\n",
    "    elif x == \"中国建设银行股份\":\n",
    "        return \"中国建设银行股份\"\n",
    "    elif x == \"中国银行股份\":\n",
    "        return \"中国银行股份\"\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_concentration = (\n",
    "            df_bank_status.assign(\n",
    "                sob=lambda x: x.apply(lambda x: big_four(x[\"bank_full_name\"]), axis =1)\n",
    "            )\n",
    "    .groupby([\"year\", \"geocode4_corr\", \"sob\"])\n",
    "            .agg({\"id\": \"count\"})\n",
    "            .sort_values(by=[\"sob\", \"geocode4_corr\", \"year\"])\n",
    "            .reset_index()\n",
    "            .pivot_table(\n",
    "                values=\"id\",\n",
    "                index=[\"sob\", \"geocode4_corr\"],\n",
    "                columns=\"year\",\n",
    "                aggfunc=np.sum,\n",
    "                fill_value=0,\n",
    "            )\n",
    "    .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"count\"})\n",
    "    .assign(\n",
    "                temp=lambda x: x.groupby([\"sob\", \"geocode4_corr\"])[\n",
    "                    \"count\"\n",
    "                ].transform(\"cumsum\"),\n",
    "                temp_1=lambda x: x.groupby([\"sob\", \"geocode4_corr\", \"temp\"])[\n",
    "                    \"year\"\n",
    "                ]\n",
    "                .transform(\"min\")\n",
    "                .fillna(\"2222\")\n",
    "                .astype(\"int\"),\n",
    "                first_entry=lambda x: x.groupby([\"sob\", \"geocode4_corr\"])[\n",
    "                    \"temp_1\"\n",
    "                ].transform(\"min\"),\n",
    "                count=lambda x: x[\"count\"].fillna(0),\n",
    "            )\n",
    "    .loc[lambda x: x[\"year\"].astype(\"int\") >= x[\"first_entry\"]]\n",
    "    .drop(columns=[\"temp\", \"temp_1\", \"first_entry\"])\n",
    "            .assign(\n",
    "                totalBranchBank=lambda x: x.groupby([\"sob\", \"geocode4_corr\"])[\n",
    "                    \"count\"\n",
    "                ].transform(\"cumsum\"),\n",
    "                totalBranchCity=lambda x: x.groupby([\"geocode4_corr\", \"year\"])[\n",
    "                    \"totalBranchBank\"\n",
    "                ].transform(\"sum\"),\n",
    "            )\n",
    "    .loc[lambda x: x[\"sob\"] != \"other\"]\n",
    "    .set_index([\"sob\", \"geocode4_corr\", \"year\", \"totalBranchCity\"])\n",
    "            .drop(columns=[\"count\"])\n",
    "            .unstack(0)\n",
    "            .assign(total_sob=lambda x: x.sum(axis=1))\n",
    "            .reset_index([\"totalBranchCity\"])\n",
    "            .assign(\n",
    "                concentration_sob=lambda x: x[(\"total_sob\", \"\")]\n",
    "                / x[(\"totalBranchCity\", \"\")]\n",
    "            )\n",
    "            .reindex(columns=[(\"total_sob\", \"\"), (\"concentration_sob\", \"\")])\n",
    "            .droplevel(axis=1, level=1)\n",
    "            .reset_index()\n",
    "            .dropna(subset=[\"concentration_sob\"])\n",
    "            .assign(concentration=lambda x: np.log((1 - x[\"concentration_sob\"]) +1)\n",
    "                   )\n",
    ")\n",
    "df_concentration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_deregulation = (\n",
    "    pd.concat([df_ccb,df_hhi], axis =1)\n",
    "    .merge(df_concentration.set_index(['year','geocode4_corr']),\n",
    "           how = 'left', left_index = True, right_index = True)\n",
    ")\n",
    "\n",
    "#df_deregulation =  pd.concat([df_ccb,df_hhi,df_concentration], axis =1)\n",
    "df_deregulation = (\n",
    "    df_deregulation.assign(\n",
    "        **{\n",
    "            \"lag_{}\".format(i): df_deregulation.groupby([\"geocode4_corr\"])[i].transform(\n",
    "                \"shift\"\n",
    "            )\n",
    "            for i in df_deregulation.columns\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_deregulation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_deregulation = (\n",
    "    df_deregulation.reindex(\n",
    "        columns=[\n",
    "            \"count_CCB\",\n",
    "            \"lag_count_CCB\",\n",
    "            \"count_no_CCB\",\n",
    "            \"lag_count_no_CCB\",\n",
    "            \"active_CCB\",\n",
    "            \"lag_active_CCB\",\n",
    "            \"active_no_CCB\",\n",
    "            \"lag_active_no_CCB\",\n",
    "            \"share_count_ccb\",\n",
    "            \"lag_share_count_ccb\",\n",
    "            \"share_active_ccb\",\n",
    "            \"lag_share_active_ccb\",\n",
    "            #\"score_count\",\n",
    "            #\"lag_score_count\",\n",
    "            #\"score_active\",\n",
    "            #\"lag_score_active\",\n",
    "            \"hhi_branches\",\n",
    "            \"lag_hhi_branches\",\n",
    "            \"hhi_branches_name\",\n",
    "            \"lag_hhi_branches_name\",\n",
    "            \"count_False\",\n",
    "            \"lag_count_False\",\n",
    "            \"count_True\",\n",
    "            \"lag_count_True\",\n",
    "            \"concentration\",\n",
    "            \"lag_concentration\",\n",
    "        ]\n",
    "    )\n",
    "    .reset_index()\n",
    "    .loc[lambda x: x[\"year\"] > \"1997\"]\n",
    ")\n",
    "df_deregulation.columns = (\n",
    "    df_deregulation.columns.str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"-\", \"_\")\n",
    "    .str.lower()\n",
    ")\n",
    "df_deregulation.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_deregulation.to_csv('df_deregulation.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def is_sequence_continuous(years):\n",
    "    sorted_years = sorted(years.unique())\n",
    "    return len(sorted_years) == sorted_years[-1] - sorted_years[0] + 1\n",
    "expected_years = list(range(1999, 2008)) \n",
    "def has_missing_years(x):\n",
    "    unique_years = x.unique()\n",
    "    return len(set(expected_years) - set(unique_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "to_download = False\n",
    "df_final1 = (\n",
    "    construct_table(table=\"firm_financial_ratio_from_pollution1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1 = (\n",
    "    df_final1\n",
    "    #.drop(columns=[\"SOE\", \"FOREIGN\"])\n",
    "    #.merge(\n",
    "    #    df_final1.assign(\n",
    "    #        first_year=lambda x: x.groupby([\"firm\"])[\"year\"].transform(\"min\")\n",
    "    #    )\n",
    "    #    .loc[lambda x: x[\"year\"] == x[\"first_year\"]]\n",
    "    #    .reindex(columns=[\"firm\", \"SOE\", \"FOREIGN\"])\n",
    "    #    .drop_duplicates()\n",
    "    #)\n",
    "    .assign(\n",
    "        change_status_soe=lambda x: x.groupby([\"firm\"])[\"SOE\"].transform(\n",
    "            lambda x: x.nunique()\n",
    "        ),\n",
    "        change_status_foreign=lambda x: x.groupby([\"firm\"])[\"FOREIGN\"].transform(\n",
    "            lambda x: x.nunique()\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1['flag_discontinuous'] = ~df_final1.groupby('firm')['year'].transform(is_sequence_continuous).astype(int)\n",
    "df_final1['missing_years'] = df_final1.groupby('firm')['year'].transform(has_missing_years)\n",
    "# Add a column to flag firms with missing years\n",
    "df_final1['flag'] = np.where(df_final1['missing_years'] > 0, 1, 0)\n",
    "df_final1 = (\n",
    "    df_final1\n",
    "    .merge(df_innovation, how = 'left', on =['year', 'geocode4_corr', 'cic_adj'])\n",
    "    .assign(\n",
    "        innovation_index =lambda x: x['innovation_index'].fillna(0),\n",
    "        innovation_index_1=lambda x: x['innovation_index_1'].fillna(0),\n",
    "        innovation_index_2=lambda x: x['innovation_index_2'].fillna(0),\n",
    "        so2_output = lambda x: x['so2']/x['output'],\n",
    "        so2_sales = lambda x: x['so2']/x['sales'],\n",
    "        so2_capital = lambda x: x['so2']/x['capital'],\n",
    "        so2_emp = lambda x: x['so2']/x['employment'],\n",
    "        so2_asset = lambda x: x['so2']/x['total_asset'],\n",
    "        \n",
    "        cod_output = lambda x: x['cod']/x['output'],\n",
    "        cod_sales = lambda x: x['cod']/x['sales'],\n",
    "        cod_capital = lambda x: x['cod']/x['capital'],\n",
    "        cod_emp = lambda x: x['cod']/x['employment'],\n",
    "        cod_asset = lambda x: x['cod']/x['total_asset'],\n",
    "        \n",
    "        waste_water_output = lambda x: x['waste_water']/x['output'],\n",
    "        waste_water_sales = lambda x: x['waste_water']/x['sales'],\n",
    "        waste_water_capital = lambda x: x['waste_water']/x['capital'],\n",
    "        waste_water_emp = lambda x: x['waste_water']/x['employment'],\n",
    "        waste_water_asset = lambda x: x['waste_water']/x['total_asset'],\n",
    "    )\n",
    "    .merge(df_deregulation.assign(year = lambda x: x['year'].astype(int)), how = 'left')\n",
    "     .merge(\n",
    "        (\n",
    "            df_credit_supply.sort_values(by=[\"province_en\", \"year\"])\n",
    "            .assign(\n",
    "                lag_credit_supply_long_term=lambda x: x.groupby([\"province_en\"])[\n",
    "                    \"credit_supply_long_term\"\n",
    "                ].transform(\"shift\")\n",
    "            )\n",
    "            .reindex(columns=[\"year\", \"province_en\", \"lag_credit_supply_long_term\",'credit_supply_long_term'])\n",
    "        ),\n",
    "         how = 'left'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#df_final1.to_csv('df_asif1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "if to_download:\n",
    "    df_final1.to_csv('df_asif1.csv')\n",
    "    df_final2 = construct_table(table=\"firm_financial_ratio_from_pollution2\")\n",
    "    df_final3 = construct_table(table=\"firm_financial_ratio_from_pollution3\")\n",
    "    \n",
    "    df_final2.to_csv('df_asif2.csv')\n",
    "    df_final3.to_csv('df_asif3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1['change_status_soe'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1['change_status_foreign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1['flag_discontinuous'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1['missing_years'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1.loc[lambda x: x['flag_discontinuous'] == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = True\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "    data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename = [\n",
    "    {\n",
    "        'old': 'current\\_ratio',\n",
    "        'new': '\\\\text{current ratio}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'cashflow\\_to\\_tangible',\n",
    "        'new': '\\\\text{cashflow}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'coverage\\_ratio',\n",
    "        'new': '\\\\text{coverage ratio}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'asset\\_tangibility\\_tot\\_asset',\n",
    "        'new': '\\\\text{asset tangibility}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'financial\\_dep\\_china1',\n",
    "        'new': '\\\\text{credit constraint}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'financial\\_dep\\_china',\n",
    "        'new': '\\\\text{credit constraint}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'lag\\_concentration',\n",
    "        'new': '\\\\text{bank regulation}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'tcz',\n",
    "        'new': '\\\\text{Two Control Zone}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'spz',\n",
    "        'new': '\\\\text{Special Policy Zone}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'tfp\\_op',\n",
    "        'new': '\\\\text{tfp}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'tofixed',\n",
    "        'new': '\\\\text{total asset}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'lag\\_sales\\_tot\\_asset',\n",
    "        'new': '\\\\text{sales to asset}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'total\\_asset',\n",
    "        'new': '\\\\text{total asset}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'employment',\n",
    "        'new': '\\\\text{employment}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'age',\n",
    "        'new': '\\\\text{age}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'age\\_sqr',\n",
    "        'new': '\\\\text{age sqr}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'dummy\\_dso2\\_equip',\n",
    "        'new': '\\\\text{$SO_{2}$ removing capacity}'\n",
    "    },\n",
    "    {\n",
    "        'old': 'SOESOE',\n",
    "        'new': '\\\\text{soe}'\n",
    "    },\n",
    "        {\n",
    "        'old': 'liabilities\\_tot\\_asset',\n",
    "        'new': '\\\\text{liabilities to asset}'\n",
    "    },\n",
    "        {\n",
    "        'old': 'concentratedTRUE',\n",
    "        'new': '\\\\text{bank regulation}'\n",
    "    },\n",
    "        {\n",
    "        'old': 'concentrated',\n",
    "        'new': '\\\\text{Bank regulation}'\n",
    "    },\n",
    "        {\n",
    "        'old': 'innovativeTRUE',\n",
    "        'new': '\\\\text{inn. capacity}'\n",
    "    },\n",
    "        {\n",
    "        'old': 'innovative',\n",
    "        'new': '\\\\text{inn. capacity}'\n",
    "    }\n",
    "        \n",
    "]\n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable df_path does not exist\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in read_csv(\"df_asif1.csv\") %>% mutate_if(is.character, as.factor) %>% : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read_csv(\"df_asif1.csv\") %>% mutate_if(is.character, as.factor) %>% : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "%get df_path\n",
    "df_final1 <- read_csv('df_asif1.csv') %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "  group_by(firm) %>%\n",
    "  mutate(count = n(), quick_ratio1 = -quick_ratio) #%>% ungroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Main results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1 = pd.read_csv('df_asif1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_final1.loc[lambda x: x['so2'] > 0]\n",
    "               .loc[lambda x: ~x['year'].isin(['1998'])]['cic_adj'].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_final1.loc[lambda x: x['so2'] > 0]\n",
    "               .loc[lambda x: ~x['year'].isin(['1998'])]['geocode4_corr'].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "    ### plot 1\n",
    "chart = sns.lmplot(x=\"log_asset_tangibility_tot_asset\",\n",
    "           y=\"so2_output\",\n",
    "           data= (\n",
    "               df_final1.assign(\n",
    "               log_asset_tangibility_tot_asset = lambda x: np.log(x['asset_tangibility_tot_asset']),\n",
    "               so2_output = lambda x: np.log(x['so2_output'])\n",
    "           )\n",
    "               .loc[lambda x: x['so2'] > 0]\n",
    "               .loc[lambda x: x['log_asset_tangibility_tot_asset'] > -4]\n",
    "               .loc[lambda x: ~x['year'].isin(['1998'])]\n",
    "           )\n",
    "                   \n",
    "                   #df.loc[lambda x: \n",
    "                   #   x['log_asset_tangibility_tot_asset'] > -4]\n",
    "          )\n",
    "plt.xlabel(\"log Asset tangibility\")\n",
    "plt.ylabel('log SO2 emissions')\n",
    "plt.savefig(\"Figures/FIGURE_3.png\",\n",
    "            bbox_inches='tight',\n",
    "            dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "fig_dims = (15, 10)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=False, figsize=fig_dims)\n",
    "\n",
    "sns.regplot(\n",
    "    x=\"log_cashflow_to_tangible\",\n",
    "    y=\"so2_output\",\n",
    "    data=(\n",
    "               df_final1.assign(\n",
    "               log_cashflow_to_tangible = lambda x: np.log(x['cashflow_to_tangible']),\n",
    "               so2_output = lambda x: np.log(x['so2_output'])\n",
    "           )\n",
    "               .loc[lambda x: x['so2'] > 0]\n",
    "               .loc[lambda x: x['cashflow_to_tangible'] > 0]\n",
    "               .loc[lambda x: ~x['year'].isin(['1998'])]\n",
    "           ),\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.set_xlabel(\"log Cashflow\")\n",
    "ax1.set_ylabel(\"log SO2 emissions\")\n",
    "sns.regplot(\n",
    "    x=\"log_current_ratio\",\n",
    "    y=\"so2_output\",\n",
    "    data=(\n",
    "               df_final1.assign(\n",
    "               log_current_ratio = lambda x: np.log(x['current_ratio']),\n",
    "               so2_output = lambda x: np.log(x['so2_output'])\n",
    "           )\n",
    "               .loc[lambda x: x['so2'] > 0]\n",
    "               .loc[lambda x: x['current_ratio'] > 0]\n",
    "               .loc[lambda x: ~x['year'].isin(['1998'])]\n",
    "           ),\n",
    "    ax=ax2,\n",
    ")\n",
    "ax2.set_xlabel(\"log Current ratio\")\n",
    "ax2.set_ylabel(\"log SO2 emissions\")\n",
    "sns.regplot(\n",
    "    x=\"log_coverage_ratio\",\n",
    "    y=\"so2_output\",\n",
    "    data=(\n",
    "               df_final1.assign(\n",
    "               log_coverage_ratio = lambda x: np.log(x['coverage_ratio']),\n",
    "               so2_output = lambda x: np.log(x['so2_output'])\n",
    "           )\n",
    "               .loc[lambda x: x['so2'] > 0]\n",
    "               .loc[lambda x: x['coverage_ratio'] > 0]\n",
    "               .loc[lambda x: ~x['year'].isin(['1998'])]\n",
    "           ),\n",
    "    ax=ax3,\n",
    ")\n",
    "ax3.set_xlabel(\"log coverage ratio\")\n",
    "ax3.set_ylabel(\"log SO2 emissions\")\n",
    "plt.savefig(\"Figures/FIGURE_4.png\",\n",
    "            bbox_inches='tight',\n",
    "            dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in df_final1 %>% mutate(age_sqr = log(age)^2, dummy_dso2_equip = ifelse(dso2_equip > : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in df_final1 %>% mutate(age_sqr = log(age)^2, dummy_dso2_equip = ifelse(dso2_equip > : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "\n",
    "t0 <- felm(log(so2_output) ~\n",
    "  log(asset_tangibility_tot_asset) + \n",
    "  log(cashflow_to_tangible) +\n",
    "  log(tfp_op) +\n",
    "  log(lag_sales_tot_asset) +  \n",
    "  log(tofixed) +\n",
    "  log(employment)+\n",
    "  log(age) + \n",
    "  age_sqr+\n",
    "             dummy_dso2_equip + \n",
    "  SOE  |\n",
    "  firm + geocode4_corr + indu_2 | 0 | indu_2, df_final1 %>%\n",
    "  mutate(\n",
    "    age_sqr = log(age) ** 2,\n",
    "      dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "\n",
    "  ) %>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible,\n",
    "        tfp_op,\n",
    "        asset_tangibility_tot_asset\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  ) %>% filter(!is.na(tfp_op))%>%\n",
    "  filter_at(\n",
    "    vars(\n",
    "      so2\n",
    "    ),\n",
    "    all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "  exactDOF = TRUE)\n",
    "\n",
    "t1 <- felm(log(so2_output) ~\n",
    "  log(asset_tangibility_tot_asset) +           \n",
    "  log(current_ratio) +\n",
    "  log(tfp_op) +\n",
    "  log(lag_sales_tot_asset) +   \n",
    "  log(tofixed) +\n",
    "  log(employment)+\n",
    "  log(age) + \n",
    "  age_sqr+\n",
    "             dummy_dso2_equip+\n",
    "  SOE  |\n",
    "  firm + geocode4_corr + indu_2 | 0 | indu_2, df_final1 %>%\n",
    "  mutate(\n",
    "    age_sqr = log(age) ** 2,\n",
    "      dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "\n",
    "  ) %>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        current_ratio,\n",
    "        tfp_op,\n",
    "        asset_tangibility_tot_asset\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  ) %>% filter(!is.na(tfp_op))%>%\n",
    "  filter_at(\n",
    "    vars(\n",
    "      so2\n",
    "    ),\n",
    "    all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "  exactDOF = TRUE)\n",
    "\n",
    "t2 <- felm(log(so2_output) ~\n",
    "  log(asset_tangibility_tot_asset) + \n",
    "  log(coverage_ratio) +\n",
    "  log(tfp_op) +\n",
    "  log(lag_sales_tot_asset) +  \n",
    "  log(tofixed) +\n",
    "  log(employment)+\n",
    "  log(age) + \n",
    "  age_sqr+\n",
    "  dummy_dso2_equip + \n",
    "  SOE  |\n",
    "  firm + geocode4_corr + indu_2 | 0 | indu_2, df_final1 %>%\n",
    "  mutate(\n",
    "    age_sqr = log(age) ** 2,\n",
    "      dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "\n",
    "  ) %>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        coverage_ratio,\n",
    "        tfp_op,\n",
    "        asset_tangibility_tot_asset\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  ) %>% filter(!is.na(tfp_op))%>%\n",
    "  filter_at(\n",
    "    vars(\n",
    "      so2\n",
    "    ),\n",
    "    all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "  exactDOF = TRUE)\n",
    "\n",
    "t3 <- felm(log(so2_output) ~\n",
    "  log(asset_tangibility_tot_asset) + \n",
    "  log(cashflow_to_tangible) +\n",
    "  log(current_ratio) +\n",
    "  log(coverage_ratio) +\n",
    "  log(tfp_op) +\n",
    "  log(lag_sales_tot_asset) +  \n",
    "  log(tofixed) +\n",
    "  log(employment)+\n",
    "  log(age) + \n",
    "  age_sqr+\n",
    "  dummy_dso2_equip +\n",
    "  SOE  |\n",
    "  firm + geocode4_corr + indu_2 | 0 | indu_2, df_final1 %>%\n",
    "  mutate(\n",
    "    age_sqr = log(age) ** 2,\n",
    "      dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "\n",
    "  ) %>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible,\n",
    "        current_ratio,\n",
    "        coverage_ratio,\n",
    "        tfp_op\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  ) %>% filter(!is.na(tfp_op))%>%\n",
    "  filter_at(\n",
    "    vars(\n",
    "      so2\n",
    "    ),\n",
    "    all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "  exactDOF = TRUE)\n",
    "\n",
    "dep <- \"Dependent variable: SO2 emission intensity\"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"year\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"city\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t0,t1, t2,t3\n",
    "),\n",
    "    title=\"Determinant of pollution emissions\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### Baseline\n",
    "\n",
    "Notebook variable calculation: https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/02_transform_tables/11_firm_pollution_financial_ratio_tfp.md\n",
    "\n",
    "**Asset Tangibility**\n",
    "The results indicate a significant positive correlation between asset tangibility and SO2 emissions. This finding aligns with the theoretical framework, suggesting that credit-constrained firms tend to invest more in tangible assets, which can be utilized as collateral. These assets are typically emission-intensive, such as heavy machinery or industrial plants, leading to higher levels of SO2 emissions. This has important policy implications, highlighting the need for regulators to reconsider the environmental costs of facilitating loans backed by tangible assets.\n",
    "\n",
    "**Internal Finance (Cash Flow, Current Ratio, Coverage Ratio)**\n",
    "Negative coefficients for variables related to internal financing capabilities—specifically cash flow, current ratio, and coverage ratio—suggest that firms with stronger internal financial health are less pollutive. Such firms are likely capable of investing in cleaner technologies or processes. This is noteworthy because these firms may be less reliant on tangible assets, reducing their environmental footprint.\n",
    "\n",
    "**Total Factor Productivity (TFP)**\n",
    "A negative coefficient for TFP indicates that firms with higher productivity levels emit less SO2. This may be due to more efficient utilization of resources per unit of output, possibly facilitated by cleaner technologies or processes. The findings related to TFP are particularly important, signaling that enhancements in productivity can be environmentally beneficial.\n",
    "\n",
    "**Control Variables**\n",
    "Although Sales to Asset, Total Asset, and Employment are used as control variables in the model, their negative correlations with SO2 emissions provide additional, albeit secondary, insights. Specifically, the findings suggest that more efficient firms in terms of resource utilization tend to have lower emissions, adding further nuance to the understanding of the interplay between corporate finance and environmental impact.\n",
    "\n",
    "In summary, the empirical evidence supports the theoretical argument that credit constraints can have unintended environmental consequences, mediated through asset tangibility. This underscores the importance of understanding the environmental implications of corporate financial decisions, especially for credit-constrained firms. The findings provide a substantive contribution to the existing literature, bridging the gap between corporate finance and environmental economics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = (\"This table estimates eq(3). \"  \n",
    "         \"\\\\textit{asset tangibility} denotes tangible assets over total assets. \"  \n",
    "         \"\\\\textit{cash flow} is defined as net income + depreciation over assets. \"  \n",
    "         \"\\\\textit{current ratio} is measured as current assets over current liabilities. \"  \n",
    "         \"\\\\textit{coverage ratio} is measured as the earning before interest and taxes over interest expenses. \"  \n",
    "         \"\\\\textit{TFP} stands for Total Factor Productivity and is estimated using the Olley and Pake algorithm. \"  \n",
    "         \"\\\\textit{$SO_{2}$ removing capacity} is the capacity to remove $SO_{2}$ emissions per hour divided by sales. \"  \n",
    "         \"All variables are in logs. Control variables are sales over asset, total asset, employment, age, age square, $SO_{2}$ removing capacity and SOE ownership \"\n",
    "         \"Heteroskedasticity-robust standard errors\"\n",
    "         \" clustered at the product level appear in parentheses.\"\n",
    "         \"\\\\sym{*} Significance at the 10\\\\%, \\\\sym{**} Significance at the 5\\\\%, \\\\sym{***} Significance at the 1\\\\%.\")\n",
    "#multicolumn ={\n",
    "#    'Eligible': 2,\n",
    "#    'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& SO2', 'COD', \"Waste water\"]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Heterogeneity effect\n",
    "\n",
    "- heterogeneity by sector and by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 2\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "year = 2001\n",
    "variable = 'innovation_index'\n",
    "threshold = .75\n",
    "(\n",
    "    df_innovation\n",
    "    .loc[lambda x: x['year'].isin([year])]\n",
    "    .groupby(['geocode4_corr'])\n",
    "    .agg({'innovation_index':'mean'})\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        median = lambda x: x[variable].quantile(threshold),\n",
    "        innovative = lambda x: x[variable] > x['median']\n",
    "    )\n",
    "    .reindex(columns = ['geocode4_corr','innovative'])\n",
    "    .to_csv('temp_innovative.csv', index = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "year = '1998'\n",
    "variable = 'hhi_branches_name'\n",
    "threshold = .75\n",
    "(\n",
    "    df_deregulation\n",
    "    .loc[lambda x: x['year'].isin([year])]\n",
    "    .assign(\n",
    "        median = lambda x: x[variable].quantile(threshold),\n",
    "        concentrated = lambda x: x[variable] > x['median']\n",
    "    )\n",
    "    .reindex(columns = ['geocode4_corr','concentrated'])\n",
    "    .to_csv('temp_regulation.csv', index = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t0 <- felm(\n",
    "    log(so2_output) ~\n",
    "      log(asset_tangibility_tot_asset) + \n",
    "      log(cashflow_to_tangible) * financial_dep_china1+\n",
    "      log(tfp_op) +\n",
    "      log(lag_sales_tot_asset) +\n",
    "      log(tofixed) +\n",
    "      log(employment) +\n",
    "      log(age) +\n",
    "      age_sqr +\n",
    "      dummy_dso2_equip +\n",
    "      SOE |\n",
    "    firm + geocode4_corr + indu_2 | 0 | indu_2, \n",
    "    df_final1 %>%\n",
    "      mutate(\n",
    "        age_sqr = log(age) ** 2,\n",
    "        dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "      ) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          cashflow_to_tangible,\n",
    "          tfp_op,\n",
    "          asset_tangibility_tot_asset\n",
    "        ),\n",
    "        all_vars(. > 0)\n",
    "      ) %>% \n",
    "      filter(!is.na(tfp_op)) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          so2\n",
    "        ),\n",
    "        all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "      )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "    exactDOF = TRUE\n",
    "  )\n",
    "\n",
    "t1 <- felm(\n",
    "    log(so2_output) ~\n",
    "      log(asset_tangibility_tot_asset) + \n",
    "      log(cashflow_to_tangible) * concentrated+\n",
    "      log(tfp_op) +\n",
    "      log(lag_sales_tot_asset) +\n",
    "      log(tofixed) +\n",
    "      log(employment) +\n",
    "      log(age) +\n",
    "      age_sqr +\n",
    "      dummy_dso2_equip +\n",
    "      SOE |\n",
    "    firm + geocode4_corr + indu_2 | 0 | indu_2, \n",
    "    df_final1 %>% left_join(read_csv('temp_regulation.csv') ) %>% mutate(concentrated = replace_na(concentrated, FALSE)) %>%\n",
    "      mutate(\n",
    "        age_sqr = log(age) ** 2,\n",
    "        dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "      ) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          asset_tangibility_tot_asset,\n",
    "          cashflow_to_tangible,\n",
    "          tfp_op\n",
    "        ),\n",
    "        all_vars(. > 0)\n",
    "      ) %>% \n",
    "      filter(!is.na(tfp_op)) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          so2\n",
    "        ),\n",
    "        all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "      )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "    exactDOF = TRUE\n",
    "  )\n",
    "\n",
    "t2 <- felm(\n",
    "    log(so2_output) ~\n",
    "      log(asset_tangibility_tot_asset) + \n",
    "      log(cashflow_to_tangible) * innovative+ \n",
    "      log(tfp_op) +\n",
    "      log(lag_sales_tot_asset) +\n",
    "      log(tofixed) +\n",
    "      log(employment) +\n",
    "      log(age) +\n",
    "      age_sqr +\n",
    "      dummy_dso2_equip +\n",
    "      SOE |\n",
    "    firm + geocode4_corr + indu_2 | 0 | indu_2, \n",
    "    df_final1 %>% left_join(read_csv('temp_innovative.csv') ) %>% mutate(innovative = replace_na(innovative, FALSE)) %>%\n",
    "      mutate(\n",
    "        age_sqr = log(age) ** 2,\n",
    "        dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "      ) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          asset_tangibility_tot_asset,\n",
    "          cashflow_to_tangible,\n",
    "          tfp_op\n",
    "        ),\n",
    "        all_vars(. > 0)\n",
    "      ) %>% \n",
    "      filter(!is.na(tfp_op)) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          so2\n",
    "        ),\n",
    "        all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "      )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "    exactDOF = TRUE\n",
    "  )\n",
    "\n",
    "t3 <- felm(\n",
    "    log(so2_output) ~\n",
    "      log(asset_tangibility_tot_asset) + \n",
    "      log(cashflow_to_tangible) * tcz+\n",
    "      log(tfp_op) +\n",
    "      log(lag_sales_tot_asset) +\n",
    "      log(tofixed) +\n",
    "      log(employment) +\n",
    "      log(age) +\n",
    "      age_sqr +\n",
    "      dummy_dso2_equip +\n",
    "      SOE |\n",
    "    firm + geocode4_corr + indu_2 | 0 | indu_2, \n",
    "    df_final1 %>%\n",
    "      mutate(\n",
    "        age_sqr = log(age) ** 2,\n",
    "        dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0),\n",
    "        tcz = ifelse(is.na(tcz), 0,tcz)\n",
    "      ) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          cashflow_to_tangible,\n",
    "          tfp_op,\n",
    "          asset_tangibility_tot_asset\n",
    "        ),\n",
    "        all_vars(. > 0)\n",
    "      ) %>% \n",
    "      filter(!is.na(tfp_op)) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          so2\n",
    "        ),\n",
    "        all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "      )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "    exactDOF = TRUE\n",
    "  )\n",
    "\n",
    "t4 <- felm(\n",
    "    log(so2_output) ~\n",
    "      log(asset_tangibility_tot_asset) + \n",
    "      log(cashflow_to_tangible) * spz+\n",
    "      log(tfp_op) +\n",
    "      log(lag_sales_tot_asset) +\n",
    "      log(tofixed) +\n",
    "      log(employment) +\n",
    "      log(age) +\n",
    "      age_sqr +\n",
    "      dummy_dso2_equip +\n",
    "      SOE |\n",
    "    firm + geocode4_corr + indu_2 | 0 | indu_2, \n",
    "    df_final1 %>%\n",
    "      mutate(\n",
    "        age_sqr = log(age) ** 2,\n",
    "        dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "      ) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          cashflow_to_tangible,\n",
    "          tfp_op,\n",
    "          asset_tangibility_tot_asset\n",
    "        ),\n",
    "        all_vars(. > 0)\n",
    "      ) %>% \n",
    "      filter(!is.na(tfp_op)) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          so2\n",
    "        ),\n",
    "        all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "      )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "    exactDOF = TRUE\n",
    "  )\n",
    "\n",
    "t5 <- felm(\n",
    "    log(so2_output) ~\n",
    "      log(asset_tangibility_tot_asset) + \n",
    "      log(cashflow_to_tangible) * financial_dep_china1+\n",
    "      log(cashflow_to_tangible) * concentrated+\n",
    "      log(cashflow_to_tangible) * innovative+\n",
    "      log(cashflow_to_tangible) * tcz+\n",
    "      log(cashflow_to_tangible) * spz+\n",
    "      log(tfp_op) +\n",
    "      log(lag_sales_tot_asset) +\n",
    "      log(tofixed) +\n",
    "      log(employment) +\n",
    "      log(age) +\n",
    "      age_sqr +\n",
    "      dummy_dso2_equip +\n",
    "      SOE |\n",
    "    firm + geocode4_corr + indu_2 | 0 | indu_2, \n",
    "    df_final1 %>% left_join(read_csv('temp_regulation.csv') ) %>% mutate(concentrated = replace_na(concentrated, FALSE))%>%\n",
    "    left_join(read_csv('temp_innovative.csv') ) %>% mutate(innovative = replace_na(innovative, FALSE)) %>%\n",
    "      mutate(\n",
    "        age_sqr = log(age) ** 2,\n",
    "        dummy_dso2_equip = ifelse(dso2_equip > 0, 1, 0)\n",
    "      ) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          cashflow_to_tangible,\n",
    "          tfp_op,\n",
    "          asset_tangibility_tot_asset\n",
    "        ),\n",
    "        all_vars(. > 0)\n",
    "      ) %>% \n",
    "      filter(!is.na(tfp_op)) %>%\n",
    "      filter_at(\n",
    "        vars(\n",
    "          so2\n",
    "        ),\n",
    "        all_vars(between(., 1, quantile(., 0.99, na.rm = TRUE)))\n",
    "      )%>%filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1)),\n",
    "    exactDOF = TRUE\n",
    "  )\n",
    "\n",
    "dep <- \"Dependent variable: SO2 emission intensity\"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"year\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"city\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t0,t1, t2,t3, t4, t5\n",
    "),\n",
    "    title=\"Heterogeneity effect\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "In this table titled \"Heterogeneity effect,\" the primary focus is on examining how SO2 emission intensity varies across different firms and situations. The idea is to test whether these variations can be explained by certain firm characteristics and interactions between these characteristics.\n",
    "\n",
    "**Main Variables:**\n",
    "1. log(cashflow): This variable measures the natural log of the firm's net income plus depreciation, scaled by assets. The coefficients across different specifications range from -0.091 to -0.078, all significant at the 1% level. This negative coefficient suggests that an increase in cashflow tends to lead to a decrease in SO2 emission intensity.\n",
    "2. Interactions with log(cashflow):\n",
    "\n",
    "    - log(cashflow) × credit constraint: The interaction term is significant and negative, with coefficients ranging from -0.037 to -0.028. This suggests that firms that are credit constrained tend to have lower SO2 emission intensity as cash flow increases, perhaps because they may invest in cleaner technologies when they have the financial means.\n",
    "    - log(cashflow) × Bank regulation: The coefficient is -0.048, significant at the 1% level, implying that stricter bank regulation combined with higher cashflow leads to lower SO2 emissions.\n",
    "    - log(cashflow) × inn. capacity: The coefficient is -0.035, significant at the 5% level. Firms with greater innovative capacity tend to reduce SO2 emissions more with an increase in cashflow.\n",
    "    - log(cashflow) × Two Control Zone: The coefficient is -0.018 and not statistically significant, suggesting that being in a \"Two Control Zone\" does not strongly influence the relationship between cashflow and SO2 emissions.\n",
    "    - log(cashflow) × Special Policy Zone: The coefficient is -0.040, significant at the 1% level, implying that firms in special policy zones tend to have lower SO2 emissions with higher cashflow, possibly due to targeted policies or incentives in these zones.\n",
    "\n",
    "**Theoretical Interpretation**:\n",
    "- log(cashflow): The negative relationship between cashflow and SO2 emission suggests that firms with more financial resources are more capable of adopting environmentally friendly practices. This aligns with the economic theory that firms with better financials can make long-term investments in cleaner technology, reducing environmental impact.\n",
    "- Interactions:\n",
    "    - Credit constraint: Firms that are credit constrained may be more sensitive to their cash situation and would invest in cleaner technologies when they have more cash, aligning with the resource-based view of the firm.\n",
    "    - Bank regulation: Stricter bank regulation may encourage firms to be more responsible environmentally, as higher cash flows may be channeled into more sustainable practices.\n",
    "    - Innovative Capacity: Firms with more innovative capacity may be more adept at deploying cash efficiently towards reducing emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "footnote = (\"This table estimates eq(3). \"\n",
    "            \"\\\\textit{Asset tangibility} represents the proportion of tangible assets to total assets. \"\n",
    "            \"\\\\textit{Cash flow} is net income plus depreciation, scaled by assets. \"\n",
    "            \"\\\\textit{TFP} is Total Factor Productivity, estimated using the Olley and Pake algorithm. \"\n",
    "            \"\\\\textit{Credit constraints} is a dummy variable taking the value of 1 if the industry is financially dependent. \"\n",
    "            \"\\\\textit{Bank regulation} is a dummy variable based on the 75th percentile of the Herfindahl-Hirschman Index calculated from the share of each bank branch relative to the total branches in that area in 1998. \"\n",
    "            \"\\\\textit{inn. capacity} is a dummy variable based on the 75th percentile of a patent value-adjusted index at the city and 4-digit industry level in 2001. \"\n",
    "            \"\\\\textit{Two Control Zone} and \\\\textit{Special Policy Zone} are policy variables indicating the firm's location. \"\n",
    "            \"Heteroskedasticity-robust standard errors clustered at the product level are in parentheses. \"\n",
    "            \"\\\\sym{*} Significance at the 10\\\\%, \\\\sym{**} Significance at the 5\\\\%, \\\\sym{***} Significance at the 1\\\\%.\")\n",
    "\n",
    "#multicolumn ={\n",
    "#    'Eligible': 2,\n",
    "#    'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& SO2', 'COD', \"Waste water\"]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = footnote,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "## Transmission channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Asset tangible, R&D and TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 3\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t0 <- felm(log(asset_tangibility_tot_asset) ~\n",
    "            log(cashflow_to_tangible) + \n",
    "            log(liabilities_tot_asset) +\n",
    "            log(total_asset) + \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t1 <- felm(rd_tot_asset_trick ~\n",
    "            log(cashflow_to_tangible) + \n",
    "            log(liabilities_tot_asset) + \n",
    "            log(total_asset) + \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible,\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  )%>%filter(year %in% list(\"2005\",\"2006\", \"2007\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t2 <- felm(log(tfp_op) ~\n",
    "            log(cashflow_to_tangible) + \n",
    "            log(liabilities_tot_asset) + \n",
    "            log(total_asset) + \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "dep <- \"Dependent variable: \"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"year\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"city\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t0,t1, t2\n",
    "),\n",
    "    title=\"Determinants of Pollution Abatement Through Asset Tangibility, RD, and TFP\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "**Asset Tangibility**: A 1% increase in cash flow leads to a 0.076% decrease in asset tangibility, holding other factors constant. This is significant at the 1% level.\n",
    "- Theoretical Explanation: Firms with more cash flow may be more flexible in their investment choices and opt for less tangible assets. This could be a sign that these firms are diverting resources towards less tangible but potentially higher-yield investments like R&D.\n",
    "- **Log(cashflow)**: Firms with higher cashflow tend to decrease their investments in tangible assets. This resonates with the understanding that when firms possess ample cash flow, they exhibit greater discretion in investment choices and are not necessitated to invest heavily in tangible assets for the sole purpose of collateralization to secure bank loans. This dynamic is particularly accentuated in environments like China where tangible assets are frequently leveraged as collateral for loan procurements.\n",
    "\n",
    "**Research and Development (RD)**: A 1% increase in cash flow leads to a 0.0005% increase in RD. This is significant at the 5% level\n",
    "- Theoretical Explanation: The positive relationship suggests that firms with more cash flow are more likely to invest in R&D. This aligns with the notion that greater cash flow can free up resources for investments in innovation.\n",
    "- **Log(cashflow)**: An upsurge in cashflow is associated with increased investments in R&D. This underscores the perspective that banks often exhibit reservations toward financing innovative endeavors due to the intangible nature of intellectual property, which cannot be readily collateralized like tangible assets. Hence, firms flush with cash are inclined to self-finance their innovative ventures, leading to elevated R&D investments.\n",
    "\n",
    "**Total Factor Productivity (TFP)**: A 1% increase in cash flow leads to a 0.087% increase in TFP, significant at the 1% level.\n",
    "- Theoretical Explanation: Greater cash flow may allow firms to invest in productivity-enhancing technologies or processes, thereby increasing their TFP.\n",
    "All the results support the idea that firms with more cash flow are more agile in their capital allocation, preferring investments that are less tangible and potentially more innovative or productive.\n",
    "- **Log(cashflow)**: Enhanced cashflow correlates with a surge in a firm's total factor productivity. This can be attributed to the possibility that firms with substantial liquidity can channel investments into state-of-the-art technologies or processes, and effectively allocate resources towards innovative or avenues promising growth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "footnote = (\"This table estimates eq(3). \"\n",
    "            \"\\\\textit{Asset tangibility} represents the proportion of tangible assets to total assets. \"\n",
    "            \"\\\\textit{RD} measures research and development expenditure. \"\n",
    "            \"\\\\textit{Cash flow} is net income plus depreciation, scaled by assets. \"\n",
    "            \"\\\\textit{TFP} is Total Factor Productivity, estimated using the Olley and Pake algorithm. \"\n",
    "            \"\\\\textit{Log(cashflow)} is the natural logarithm of cash flow. \"\n",
    "            \"Heteroskedasticity-robust standard errors clustered at the product level are in parentheses. \"\n",
    "            \"\\\\sym{*} Significance at the 10\\\\%, \\\\sym{**} Significance at the 5\\\\%, \\\\sym{***} Significance at the 1\\\\%.\")\n",
    "\n",
    "\n",
    "#multicolumn ={\n",
    "#    'Eligible': 2,\n",
    "#    'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& Asset tangibility', 'RD', \"TFP\"]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = footnote,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "Credit constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 4\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "\n",
    "t0 <- felm(log(asset_tangibility_tot_asset) ~\n",
    "            log(cashflow_to_tangible)* financial_dep_china1 + \n",
    "            log(liabilities_tot_asset) + \n",
    "            log(total_asset) + \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t1 <- felm(rd_tot_asset_trick ~\n",
    "            log(cashflow_to_tangible) * financial_dep_china1+ \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) + \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "             age_sqr = age **2,\n",
    "         )%>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible,\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  )%>%filter(year %in% list(\"2005\",\"2006\", \"2007\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t2 <- felm(log(tfp_op) ~\n",
    "            log(cashflow_to_tangible) * financial_dep_china1+ \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) + \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "dep <- \"Dependent variable: \"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"year\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"city\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t0,t1, t2\n",
    "),\n",
    "    title=\"Impact of Credit Constraints on Tangibility, RD, and TFP in Pollution Control\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "From the outlined mechanisms:\n",
    "\n",
    "- Financial constraints, through by cash flow, wield significant influence over a firm's investment strategies. With augmented cash flow, firms, especially private entities that might be marginalized by predominant banks, exercise autonomy in investment decisions. Rather than allocating resources to tangible assets, predominantly viewed as a vehicle to procure loans, there's a palpable shift towards innovation (R&D) — an avenue that holds the promise of sustained growth and heightened efficiency.\n",
    "\n",
    "- This trend is emblematic of a broader economic shift where, sufforing by financial constraints, firms prioritize long-term growth, innovation, and efficiency over transient needs or the acquisition of external finance. Within a framework where traditional bank loans could be elusive for a subset of firms, especially against a landscape of credit concentration and preferential lending patterns favoring SOEs, internal cash reserves assume paramount importance in guiding investment choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "footnote = (\"This table estimates eq(3). \"\n",
    "            \"\\\\textit{Asset tangibility} represents the proportion of tangible assets to total assets. \"\n",
    "            \"\\\\textit{RD} measures research and development expenditure. \"\n",
    "            \"\\\\textit{Cash flow} is net income plus depreciation, scaled by assets. \"\n",
    "            \"\\\\textit{TFP} is Total Factor Productivity, estimated using the Olley and Pake algorithm. \"\n",
    "            \"\\\\textit{Credit constraints} is a dummy variable taking the value of 1 if the industry is financially dependent. \"\n",
    "            \"Heteroskedasticity-robust standard errors clustered at the product level are in parentheses. \"\n",
    "            \"\\\\sym{*} Significance at the 10\\\\%, \\\\sym{**} Significance at the 5\\\\%, \\\\sym{***} Significance at the 1\\\\%.\")\n",
    "#multicolumn ={\n",
    "#    'Eligible': 2,\n",
    "#    'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& Asset tangibility', 'RD', \"TFP\"]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = footnote,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "Removal capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "list_vars = ['rlmxf',\n",
    " 'ylmxf',\n",
    " 'rlmpjlf',\n",
    " 'rlyxf',\n",
    " 'zyxf',\n",
    " 'cyxf',\n",
    " 'rlypjlf',\n",
    " 'zypjlf',\n",
    " 'clean_gas_used',\n",
    " 'waste_water',\n",
    " 'cod',\n",
    " 'ad',\n",
    " 'waste_gas',\n",
    " 'so2',\n",
    " 'nox',\n",
    " 'smoke_dust',\n",
    " 'soot',\n",
    " 'yfc',\n",
    " 'gyfscll',\n",
    " 'hxxyqcl',\n",
    " 'xzssqcl',\n",
    " 'adqcl',\n",
    " 'eyhlqcl',\n",
    " 'dyhwqcl',\n",
    " 'ycqcl',\n",
    " 'gyfcqcl',\n",
    " 'dwastewater_equip',\n",
    " 'fszlssnl',\n",
    " 'fszlssfee',\n",
    " 'dwastegas_equip',\n",
    " 'dso2_equip',\n",
    " 'fqzlssnl',\n",
    " 'tlssnl',\n",
    " 'hxxycsl',\n",
    " 'adcsl',\n",
    " 'eyhlcsl',\n",
    " 'dyhwcsl',\n",
    " 'yfccsl',\n",
    "            'tlssnl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### Investment in Pollution Abatement:\n",
    "\n",
    "- Abatement Capacity: This term refers to the collective technological and infrastructural capabilities a firm possesses for reducing sulfur dioxide (SO2) emissions. It captures the extent to which a company can minimize its environmental impact through various abatement strategies, whether through end-of-pipe solutions or more integrated, process-level innovations.\n",
    "- SO2 Removed: This metric denotes the actual volume of sulfur dioxide (SO2) emissions that a firm has successfully eliminated during a specific time frame, such as an annual reporting period. This provides a concrete measure of a firm's effectiveness in reducing its environmental footprint and can serve as an indicator for regulatory compliance and social responsibility.\n",
    "- SO2 Removal Per Hour: This variable quantifies the rate at which a company is capable of eliminating SO2 emissions. It provides an efficiency measure, allowing for the assessment of how quickly a firm can respond to environmental challenges and adjust its operations to reduce pollutants effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 5\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "\n",
    "t0 <- felm(log(dso2_equip + 1) ~\n",
    "            log(cashflow_to_tangible) + \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) +  \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE\n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "             age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t1 <- felm(log(eyhlqcl + 1) ~\n",
    "            log(cashflow_to_tangible) + \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) +  \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible,\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "     ,\n",
    "     exactDOF = TRUE)\n",
    "\n",
    "t2 <- felm(log(tlssnl+1) ~\n",
    "            log(cashflow_to_tangible) + \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) +  \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1%>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))%>%filter(!is.na(financial_dep_china1))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "dep <- \"Dependent variable: \"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"year\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"city\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t0,t1, t2\n",
    "),\n",
    "    title=\"Role of Cashflows in Pollution Abatement\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "**Abatement capacity**:\n",
    "\n",
    "- Interpretation with Log(cashflow): The coefficient of log(cashflow) in predicting abatement capacity is 0.006 and is not statistically significant. This indicates that, within the scope of this dataset, an increase in cashflow does not necessarily lead to a measurable rise in a firm's pollution abatement capacity. Firms with a higher cashflow are found to increase their abatement capacity, implying that an increase in liquidity allows firms to invest in technologies and systems that enhance their capacity to reduce pollution. This suggests a proactive response by liquidity-rich firms in environmental stewardship.\n",
    "\n",
    "- Theoretical Explanation: The theoretical framework suggests that firms with higher cashflow should have the financial flexibility to invest in pollution abatement technologies. However, the empirical evidence does not support this hypothesis for abatement capacity. It is possible that firms allocate their excess cash to investments deemed more urgent or beneficial, a topic that could be explored in future research.\n",
    "\n",
    "**SO2 Removed**:\n",
    "- Interpretation with Log(cashflow): A positive and highly statistically significant coefficient of 0.099 for log(cashflow) indicates that firms with higher cashflows are effectively utilizing their resources to remove a greater amount of SO2 emissions. Higher cashflows lead to a significant increase in the amount of SO2 removed. Firms that possess ample liquidity are, evidently, deploying it to enhance their environmental footprint by adopting more efficient pollution abatement technologies.\n",
    "\n",
    "- Theoretical Explanation: This finding is consistent with the theoretical premise that liquidity-rich firms are more capable of allocating funds to environmentally beneficial technologies. The significant coefficient may reflect firms' proactive responses to social pressures and potential regulatory incentives.\n",
    "\n",
    "**SO2 Removal Per Hour**:\n",
    "\n",
    "- Interpretation with Log(cashflow): The coefficient of 0.022 for log(cashflow) is statistically significant at the 10% level, implying that firms with greater cashflow are not just increasing their capacity to remove SO2, but are doing so more efficiently on an hourly basis. An increase in cashflow correlates with more efficient hourly SO2 removal rates. This implies that liquidity not only aids in sheer volume but also in the efficiency of the pollution control mechanisms.\n",
    "\n",
    "- Theoretical Explanation: The positive and statistically significant coefficient aligns with the theoretical expectation that firms with more liquidity invest not only in the scale but also in the efficiency of their pollution abatement activities. This could be interpreted as a strategic focus on sustainable operations, possibly motivated by regulatory pressures and internal corporate commitments to sustainability.\n",
    "\n",
    "These interpretations and theoretical discussions aim to elucidate the relationships observed in the data, providing both empirical and conceptual insights into the determinants of pollution abatement activities among firms.\n",
    "\n",
    "In summary, the results shed light on the pivotal role that liquidity, in the form of cashflow, plays in a firm's environmental endeavors, specifically in the realm of SO2 abatement. It further underscores the nuanced ways in which firm size, leverage, age, and ownership influence environmental responsiveness in the context of SO2 pollution control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "footnote = (\"This table estimates eq(3). \"\n",
    "            \"\\\\textit{Abatement Capacity} refers to the firm's equipment designed to mitigate SO2 emissions. \"\n",
    "            \"\\\\textit{SO2 Removed} quantifies the annual amount of SO2 mitigated by the firm through end-of-pipe solutions following production. \"\n",
    "            \"\\\\textit{SO2 Removal Per Hour} represents the rate at which SO2 is eliminated, measured in kilograms per hour. \"\n",
    "            \"\\\\textit{Cash flow} is net income plus depreciation, scaled by assets. \"\n",
    "            \"Heteroskedasticity-robust standard errors clustered at the product level are in parentheses. \"\n",
    "            \"\\\\sym{*} Significance at the 10\\\\%, \\\\sym{**} Significance at the 5\\\\%, \\\\sym{***} Significance at the 1\\\\%.\")\n",
    "\n",
    "\n",
    "multicolumn ={\n",
    "    'SO2': 2,\n",
    "    'COD': 2,\n",
    "    'Waste water': 2\n",
    "}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& Abatement capacity', 'SO2 removed', 'SO2 removal per hour']\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = footnote,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Credit constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 6\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t0 <- felm(log(dso2_equip + 1) ~\n",
    "            log(cashflow_to_tangible) * financial_dep_china+ \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) +  \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE\n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t1 <- felm(log(eyhlqcl + 1) ~\n",
    "            log(cashflow_to_tangible) * financial_dep_china+ \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) +  \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE\n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1 %>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "        filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible,\n",
    "\n",
    "    ),\n",
    "    all_vars(. >0)\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))\n",
    "     ,\n",
    "     exactDOF = TRUE)\n",
    "\n",
    "t2<- felm(log(tlssnl+1) ~\n",
    "            log(cashflow_to_tangible) * financial_dep_china+ \n",
    "            log(liabilities_tot_asset) +  \n",
    "            log(total_asset) +  \n",
    "            log(employment)+\n",
    "            log(age) +\n",
    "            age_sqr +\n",
    "             SOE \n",
    "            |firm + geocode4_corr+indu_2|0 | indu_2, df_final1%>%\n",
    "            mutate(\n",
    "              age_sqr = log(age) **2,\n",
    "         )%>%\n",
    "             filter_at(\n",
    "    vars(\n",
    "        cashflow_to_tangible\n",
    "    ),\n",
    "all_vars(between(., 0.01, quantile(., 0.99, na.rm = TRUE)))\n",
    "  )%>%\n",
    "                 filter(!year %in% list(\"1998\"))\n",
    "             ,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "dep <- \"Dependent variable: \"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"year\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"city\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t0,t1, t2\n",
    "),\n",
    "    title=\"Effects of Cashflow on Pollution Abatement in Credit-Constrained Firms\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "**Abatement capacity**:\n",
    "\n",
    "- Interpretation with Cashflow: The coefficient for log(cashflow) has increased and is now significant at the 5% level. This indicates a stronger positive relationship between higher cashflows and the firm's investment in pollution abatement capacity.\n",
    "- Theoretical Explanation: The presence of a significant interaction term between cashflow and credit constraint suggests that firms in credit-constrained sectors are even more likely to invest in pollution abatement when they have higher cashflows. This can be interpreted as firms in financially restricted sectors taking advantage of liquidity to address a pressing issue they otherwise would not have the resources for.\n",
    "\n",
    "**SO2 Removed**:\n",
    "\n",
    "- Interpretation with Cashflow: The coefficient is higher and remains highly significant, implying that firms with greater cashflows are able to significantly enhance their SO2 removal capabilities.\n",
    "- Theoretical Explanation: The significant interaction term between cashflow and credit constraint underscores the importance of liquidity in enabling firms, particularly those in credit-constrained industries, to invest in effective pollution abatement technologies. This implies that for firms in such constrained sectors, liquidity may be an especially valuable resource for making environmentally responsible choices.\n",
    "\n",
    "**SO2 Removal per Hour**:\n",
    "\n",
    "- Interpretation with Cashflow: The coefficient has doubled compared to previous findings and is significant at the 5% level. This suggests that firms with higher liquidity are not just reducing more pollution but are doing so more efficiently.\n",
    "- Theoretical Explanation: The significance of the interaction term between cashflow and credit constraint suggests that credit-constrained firms regard efficient pollution control not just as a social responsibility but as a strategic necessity. When such firms experience an increase in cashflow, they are more likely to allocate this liquidity towards enhancing their pollution control mechanisms' efficiency.\n",
    "\n",
    "In this way, the results collectively emphasize that firms with better cashflow positions are more proactive in pollution control, especially in credit-constrained sectors. This underscores the importance of financial liquidity in the fight against industrial pollution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "footnote = (\"This table estimates eq(3). \"\n",
    "            \"\\\\textit{Abatement Capacity} refers to the firm's equipment designed to mitigate SO2 emissions. \"\n",
    "            \"\\\\textit{SO2 Removed} quantifies the annual amount of SO2 mitigated by the firm through end-of-pipe solutions following production. \"\n",
    "            \"\\\\textit{SO2 Removal Per Hour} represents the rate at which SO2 is eliminated, measured in kilograms per hour. \"\n",
    "            \"\\\\textit{Cash flow} is net income plus depreciation, scaled by assets. \"\n",
    "            \"\\\\textit{Credit constraints} is a dummy variable taking the value of 1 if the industry is financially dependent. \"\n",
    "            \"Heteroskedasticity-robust standard errors clustered at the product level are in parentheses. \"\n",
    "            \"\\\\sym{*} Significance at the 10\\\\%, \\\\sym{**} Significance at the 5\\\\%, \\\\sym{***} Significance at the 1\\\\%.\")\n",
    "\n",
    "\n",
    "multicolumn ={\n",
    "    'SO2': 2,\n",
    "    'COD': 2,\n",
    "    'Waste water': 2\n",
    "}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& Abatement capacity', 'SO2 removed', 'SO2 removal per hour']\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = footnote,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import make_toc\n",
    "import create_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "name_json = 'parameters_ETL_pollution_credit_constraint.json'\n",
    "path_json = os.path.join(str(Path(path).parent.parent), 'utils',name_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report.create_report(extension = \"html\", keep_code = False, notebookname = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Update TOC in Github\n",
    "for p in [parent_path,\n",
    "          str(Path(path).parent),\n",
    "          #os.path.join(str(Path(path).parent), \"00_download_data_from\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"00_statistical_exploration\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"01_model_estimation\"),\n",
    "         ]:\n",
    "    try:\n",
    "        os.remove(os.path.join(p, 'README.md'))\n",
    "    except:\n",
    "        pass\n",
    "    path_parameter = os.path.join(parent_path,'utils', name_json)\n",
    "    md_lines =  make_toc.create_index(cwd = p, path_parameter = path_parameter)\n",
    "    md_out_fn = os.path.join(p,'README.md')\n",
    "    \n",
    "    if p == parent_path:\n",
    "    \n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = True, path_parameter = path_parameter)\n",
    "    else:\n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --no-input --to html 09_firm_level_estimation_pollution_2.ipynb"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
