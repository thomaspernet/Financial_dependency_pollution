{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Model estimate Estimate pollution abatement equipment and internal finance\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "None\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: 317_Financial_dependency_pollution\n",
    "- Epic: Models\n",
    "- US: Evaluate econometrics model\n",
    "- Task tag: #econometrics-strategy, #pollution-abatement-equipment, #training-Financial-dependency-pollution\n",
    "- Analytics reports: \n",
    "\n",
    "# Input\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name**\n",
    "\n",
    "None\n",
    "\n",
    "**Github**\n",
    "\n",
    "- https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/02_data_analysis/01_model_train_evaluate/00_estimate_fin_ratio/07_pollution_abatement_equation.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-2'\n",
    "bucket = 'datalake-london'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'environment'\n",
    "table = 'fin_dep_pollution_baseline_city'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = True\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalogue/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM {}.{}\n",
    "    WHERE \n",
    "      year in (\n",
    "        '2001', '2002', '2003', '2004', '2005', \n",
    "        '2006', '2007'\n",
    "      ) \n",
    "      AND \n",
    "      lag_current_ratio > 0 \n",
    "      AND\n",
    "      lag_cashflow_to_tangible > 0 \n",
    "      AND \n",
    "      tfp_cit > 0\n",
    "    \"\"\".format(db, table)\n",
    "    df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename=filename,  # Add filename to print dataframe\n",
    "        destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        dtype = dtypes\n",
    "    )\n",
    "    .sort_values(by = ['geocode4_corr','ind2', 'year'])\n",
    "    .assign(\n",
    "        tso2_eq_output = lambda x: (x['tdso2_equip'])/(x['output']/1000),\n",
    "        tso2_eq_output_1 = lambda x: (x['tdso2_equip']+1)/(x['output']/1000),\n",
    "        tso2_eq_asset = lambda x: (x['tdso2_equip'])/(x['total_asset']/1000),\n",
    "        tso2_eq_asset_1 = lambda x: (x['tdso2_equip']+1)/(x['total_asset']/1000),\n",
    "        constraint = lambda x: x['credit_constraint'] > -0.44,\n",
    "        constraint_1 = lambda x: x['credit_constraint'] > -0.26,\n",
    "        target = lambda x: np.where(x['tdso2_equip'] > 0, 1,0),\n",
    "        intensity=lambda x: x[\"ttlssnl\"]/ x[\"sales\"]\n",
    "    )\n",
    "         )\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df.reindex(columns = ['geocode4_corr','ind2', 'year',\n",
    "                      'tso2_eq_output_1', \n",
    "                      'pct_change_eq', \n",
    "                      \"std_eq_ind\",\n",
    "                      \"std_eq_c\",\n",
    "                      \"std_eq_year\",\n",
    "                      'std_eq',\n",
    "                      \"lag_cashflow_to_tangible\",\n",
    "                      \"lag_current_ratio\",\n",
    "                      \"pct_change_eq_raw\",\n",
    "                     \"pct_change_cash\", \n",
    "                     'pct_change_curr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path_local, filename + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df[['credit_constraint', 'constraint']].drop_duplicates().sort_values(by = ['credit_constraint'])\n",
    "    .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = True\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "        data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename =  [\n",
    "        {\n",
    "        'old':'periodTRUE',\n",
    "        'new':'\\\\text{period}'\n",
    "        },\n",
    "        ### depd\n",
    "        {\n",
    "        'old':'total\\_asset',\n",
    "        'new':'\\\\text{total asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'tangible',\n",
    "        'new':'\\\\text{tangible asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'investment\\_tot\\_asset',\n",
    "        'new':'\\\\text{investment to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'rd\\_tot\\_asset',\n",
    "        'new':'\\\\text{rd to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'asset\\_tangibility\\_tot\\_asset',\n",
    "        'new':'\\\\text{asset tangibility}'\n",
    "        },\n",
    "        \n",
    "        ### ind\n",
    "        {\n",
    "        'old':'current\\_ratio',\n",
    "        'new':'\\\\text{current ratio}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_current\\_ratio',\n",
    "        'new':'\\\\text{current ratio}'\n",
    "        },\n",
    "        {\n",
    "        'old':'quick\\_ratio',\n",
    "        'new':'\\\\text{quick ratio}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_liabilities\\_tot\\_asset',\n",
    "        'new':'\\\\text{liabilities to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'liabilities\\_tot\\_asset',\n",
    "        'new':'\\\\text{liabilities to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'sales\\_tot\\_asset',\n",
    "        'new':'\\\\text{sales to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_sales\\_tot\\_asset',\n",
    "        'new':'\\\\text{sales to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cash\\_tot\\_asset',\n",
    "        'new':'\\\\text{cash to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cashflow\\_tot\\_asset',\n",
    "        'new':'\\\\text{cashflow to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cashflow\\_to\\_tangible',\n",
    "        'new':'\\\\text{cashflow}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_cashflow\\_to\\_tangible',\n",
    "        'new':'\\\\text{cashflow}'\n",
    "        },\n",
    "        {\n",
    "        'old':'d\\_credit\\_constraintBELOW',\n",
    "        'new':'\\\\text{Fin dep}_{i}'\n",
    "        },\n",
    "        ## control\n",
    "        {\n",
    "        'old':'age + 1',\n",
    "        'new':'\\\\text{age}'\n",
    "        },\n",
    "        {\n",
    "        'old':'export\\_to\\_sale',\n",
    "        'new':'\\\\text{export to sale}'\n",
    "        },\n",
    "        {\n",
    "        'old':'labor\\_capital',\n",
    "        'new':'\\\\text{labor to capital}'\n",
    "        },\n",
    "        ### Supply demand external finance\n",
    "        {\n",
    "        'old':'supply\\_all\\_credit',\n",
    "        'new':'\\\\text{all credit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'supply\\_long\\_term\\_credit',\n",
    "        'new':'\\\\text{long term credit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'credit\\_constraint',\n",
    "        'new':'\\\\text{credit demand}'\n",
    "        },\n",
    "        {\n",
    "        'old':'soe\\_vs\\_priPRIVATE',\n",
    "        'new':'\\\\text{private}'\n",
    "        },\n",
    "        ## TFP\n",
    "        {\n",
    "        'old':'tfp\\_cit',\n",
    "        'new':'\\\\text{TFP}'\n",
    "        },\n",
    "        {\n",
    "        'old':'industry\\_size',\n",
    "        'new':'\\\\text{industry size}'\n",
    "        },\n",
    "        {\n",
    "        'old':'constraintTRUE',\n",
    "        'new':'\\\\text{constraint}'\n",
    "        }\n",
    "        \n",
    "    ]\n",
    "    \n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "library(fixest)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "#library('emmeans')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "mutate(\n",
    "    constraint = relevel(as.factor(constraint), ref='FALSE'),\n",
    "    constraint_test = relevel(as.factor(constraint), ref='TRUE'),\n",
    "    constraint_1 = relevel(as.factor(constraint_1), ref='FALSE'),\n",
    ")%>% filter(tdso2_equip <52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "Is the data correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 1: Pollution abatement channel\n",
    "\n",
    "$$\\begin{aligned} \\text{Equipment}_{cit} &=  \\alpha_2 \\text{Internal finance}_{cit-1}+\\beta \\text{X}_{cit} + \\gamma_{it} +\\gamma_{ct} + \\epsilon_{cit} \\end{aligned}$$\n",
    "\n",
    "The following variables are lagged:\n",
    "\n",
    "- cashflow\n",
    "- current ratio\n",
    "- sale over asset\n",
    "\n",
    "- Internal finance is a driver of pollution abatement systems\n",
    "- The acquisition of pollution abatement systems is realized in a dissimilar way: \n",
    "    - Small firms use their cashflow to invest while large firms can use a credit because they have a collateral and are less constraint than small firms\n",
    "\n",
    "Follow methodology: [Greening Through Finance?](https://drive.google.com/file/d/1E6hPTzv6CPgR-uJydgzhcfN2G-CjFUWu/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Count & Probits models\n",
    "\n",
    "More about count data:  [Poisson Regression Models](https://www.dataquest.io/blog/tutorial-poisson-regression-in-r/#:~:text=A%20Poisson%20Regression%20model%20is,form%20by%20some%20unknown%20parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "#library(alpaca)\n",
    "\n",
    "#library(texreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "#t_0 = fepois(\n",
    "#    tdso2_equip ~ \n",
    "#            log(cashflow_to_tangible) +\n",
    "#            #log(current_ratio) +\n",
    "#            log(lag_liabilities_tot_asset) +\n",
    "#            log(lag_sales_tot_asset)+\n",
    "#            log(total_asset)\n",
    "#            | fe_t_i + fe_c_t,df_final\n",
    "#)\n",
    "#t_1 <- fepois(tdso2_equip ~ \n",
    "#            #log(cashflow_to_tangible)+\n",
    "#            log(current_ratio) +\n",
    "#            log(lag_liabilities_tot_asset) +\n",
    "#            log(lag_sales_tot_asset)+\n",
    "#            log(total_asset)\n",
    "#            | fe_t_i + fe_c_t,df_final\n",
    "#    )\n",
    "\n",
    "t_2 <- fepois(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible)+\n",
    "            log(current_ratio) +\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t,df_final\n",
    "    )\n",
    "\n",
    "t_3 <- fepois(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible) * log(total_asset)+\n",
    "            #log(current_ratio) * log(total_asset)+\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t,df_final\n",
    "    )\n",
    "\n",
    "t_4 <- fepois(tdso2_equip ~ \n",
    "            #log(cashflow_to_tangible) * log(total_asset)+\n",
    "            log(current_ratio) * log(total_asset)+\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t,df_final\n",
    "    )\n",
    "\n",
    "t_5 <- fepois(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible) * log(total_asset)+\n",
    "            log(current_ratio) * log(total_asset)+\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t,df_final\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "print(etable(# t_0,t_1, \n",
    "             t_2, t_3,t_4,t_5,\n",
    "         vcov = \"iid\",\n",
    "       headers = c(\"1\", \"2\", \"3\", \"4\"),\n",
    "       tex = TRUE,\n",
    "       digits = 3,\n",
    "      digits.stats = 3\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# SOE vs Private\n",
    "\n",
    "City ownership are available for the following variables:\n",
    "\n",
    "- output\n",
    "- capital\n",
    "- employment\n",
    "- sales\n",
    "\n",
    "**How is it constructed** \n",
    "\n",
    "* city ownership public vs private in 2002\n",
    "  * Aggregate output by ownership and city\n",
    "    * A given city will have SOE asset tangibility and PRIVATE asset tangibility [output, employment, capital and sales]\n",
    "  * If asset tangibility SOE above Private then city is dominated by SOE\n",
    "  \n",
    "Notebook reference: https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/02_transform_tables/07_dominated_city_ownership.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH test AS (\n",
    "  SELECT \n",
    "    *,\n",
    "    CASE WHEN LENGTH(cic) = 4 THEN substr(cic, 1, 2) ELSE concat(\n",
    "      '0', \n",
    "      substr(cic, 1, 1)\n",
    "    ) END AS indu_2,\n",
    "    CASE WHEN ownership = 'SOE' THEN 'SOE' ELSE 'PRIVATE' END AS soe_vs_pri,\n",
    "    CASE WHEN ownership in ('HTM', 'FOREIGN') THEN 'FOREIGN' ELSE 'DOMESTIC' END AS for_vs_dom \n",
    "  FROM \n",
    "    firms_survey.asif_firms_prepared \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised \n",
    "      GROUP BY \n",
    "        extra_code, \n",
    "        geocode4_corr\n",
    "    ) as no_dup_citycode ON asif_firms_prepared.citycode = no_dup_citycode.extra_code\n",
    "  \n",
    ") \n",
    "SELECT year, soe, geocode4_corr, indu_2,SUM(output) as output, SUM(employ) as employ, SUM(captal) as capital\n",
    "FROM (\n",
    "SELECT *,\n",
    "CASE WHEN ownership in ('SOE') THEN 'SOE' ELSE 'PRIVATE' END AS soe\n",
    "FROM test \n",
    "  )\n",
    "  GROUP BY soe, geocode4_corr, year, indu_2\n",
    "\"\"\"\n",
    "df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename=\"test\",  # Add filename to print dataframe\n",
    "        destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        dtype = dtypes\n",
    "    )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Dirty code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "for v in ['output','employ', 'capital']:\n",
    "    for t in [.5, .4, .3, .2, .1]:\n",
    "        df_ = (\n",
    "            df\n",
    "            .set_index(['year','indu_2', 'soe', 'geocode4_corr'])\n",
    "            .unstack(-2)\n",
    "            .assign(\n",
    "                soe_dominated = lambda x: x[(v, 'SOE')] > x[(v, 'PRIVATE')],\n",
    "                share_soe = lambda x: x[(v, 'SOE')] / (x[(v, 'SOE')] + x[(v, 'PRIVATE')])\n",
    "            )\n",
    "            #.loc[lambda x: x['soe_dominated'].isin([True])]\n",
    "            .collapse_levels(\"_\")\n",
    "            .reset_index()\n",
    "            [['year','geocode4_corr', 'indu_2', \"soe_dominated\", \n",
    "             'share_soe'\n",
    "             ]]\n",
    "            .loc[lambda x: x['year'].isin([\"2002\"])]\n",
    "            .drop(columns = ['year'])\n",
    "            .rename(columns = {'indu_2':'ind2'})\n",
    "            .loc[lambda x: x['share_soe']> t]\n",
    "            #.groupby(['soe_dominated'])\n",
    "            #.agg({'share_soe':'describe'})\n",
    "            .to_csv('list_city_soe_{}_{}.csv'.format(v, t), index = False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH test AS (\n",
    "  SELECT \n",
    "    *,\n",
    "    CASE WHEN LENGTH(cic) = 4 THEN substr(cic, 1, 2) ELSE concat(\n",
    "      '0', \n",
    "      substr(cic, 1, 1)\n",
    "    ) END AS indu_2,\n",
    "    CASE WHEN ownership = 'SOE' THEN 'SOE' ELSE 'PRIVATE' END AS soe_vs_pri,\n",
    "    CASE WHEN ownership in ('HTM', 'FOREIGN') THEN 'FOREIGN' ELSE 'DOMESTIC' END AS for_vs_dom \n",
    "  FROM \n",
    "    firms_survey.asif_firms_prepared \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised \n",
    "      GROUP BY \n",
    "        extra_code, \n",
    "        geocode4_corr\n",
    "    ) as no_dup_citycode ON asif_firms_prepared.citycode = no_dup_citycode.extra_code\n",
    "  \n",
    ") \n",
    "SELECT year, foreign, geocode4_corr, indu_2,SUM(output) as output, SUM(employ) as employ, SUM(captal) as capital\n",
    "FROM (\n",
    "SELECT *,\n",
    "CASE WHEN ownership in ('HTM', 'FOREIGN') THEN 'FOREIGN' ELSE 'DOMESTIC' END AS foreign\n",
    "FROM test \n",
    "  )\n",
    "  GROUP BY foreign, geocode4_corr, year, indu_2\n",
    "\n",
    "\"\"\"\n",
    "df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename=\"test\",  # Add filename to print dataframe\n",
    "        destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        dtype = dtypes\n",
    "    )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "for v in ['output','employ', 'capital']:\n",
    "    for t in [.5, .4, .3, .2, .1]:\n",
    "        (\n",
    "            df\n",
    "            .set_index(['year','indu_2', 'foreign', 'geocode4_corr'])\n",
    "            .unstack(-2)\n",
    "            .assign(\n",
    "                for_dominated = lambda x: x[(v, 'FOREIGN')] > x[(v, 'DOMESTIC')],\n",
    "                share_for = lambda x: x[(v, 'FOREIGN')] / (x[(v, 'FOREIGN')] + x[(v, 'DOMESTIC')])\n",
    "            )\n",
    "            .collapse_levels(\"_\")\n",
    "            .reset_index()\n",
    "            [['year','geocode4_corr', 'indu_2', \"for_dominated\", \n",
    "             'share_for'\n",
    "             ]]\n",
    "            .loc[lambda x: x['year'].isin([\"2002\"])]\n",
    "            .drop(columns = ['year'])\n",
    "            .rename(columns = {'indu_2':'ind2'})\n",
    "            .loc[lambda x: x['share_for']> t]\n",
    "            #.groupby(['soe_dominated'])\n",
    "            #.agg({'share_soe':'describe'})\n",
    "            .to_csv('list_city_for_{}_{}.csv'.format(v, t), index = False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "In the paper, only output is reported:\n",
    "\n",
    "- 50%, 40% and 30% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "df_soe <- df_final %>% inner_join(read_csv('list_city_soe_output_0.5.csv'))\n",
    "df_priv <- df_final %>% left_join(read_csv('list_city_soe_output_0.5.csv')) %>% filter(is.na(share_soe))\n",
    "df_for <- df_final %>% inner_join(read_csv('list_city_for_output_0.5.csv'))\n",
    "df_dom <- df_final %>% left_join(read_csv('list_city_for_output_0.5.csv')) %>% filter(is.na(share_for))\n",
    "\n",
    "#### SOE\n",
    "t_0 <- feglm(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible)+\n",
    "            log(current_ratio) +\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t|0 | geocode4_corr,df_soe \n",
    "               ,\n",
    "         poisson(link = \"log\")\n",
    "    )\n",
    "\n",
    "#### PRIVATE\n",
    "t_1 <- feglm(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible)+\n",
    "            log(current_ratio) +\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t|0 | geocode4_corr,df_priv \n",
    "               ,\n",
    "         poisson(link = \"log\")\n",
    "    )\n",
    "\n",
    "#### FOREIGN\n",
    "t_2 <- feglm(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible)+\n",
    "            log(current_ratio) +\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t|0 | geocode4_corr,df_for \n",
    "               ,\n",
    "         poisson(link = \"log\")\n",
    "    )\n",
    "\n",
    "#### DOMESTIC\n",
    "t_3 <- feglm(tdso2_equip ~ \n",
    "            log(cashflow_to_tangible)+\n",
    "            log(current_ratio) +\n",
    "            log(lag_liabilities_tot_asset) +\n",
    "            log(lag_sales_tot_asset)+\n",
    "            log(total_asset)\n",
    "            | fe_t_i + fe_c_t|0 | geocode4_corr,df_dom \n",
    "               ,\n",
    "         poisson(link = \"log\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(t_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import make_toc\n",
    "import create_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "name_json = 'parameters_ETL_pollution_credit_constraint.json'\n",
    "path_json = os.path.join(str(Path(path).parent.parent), 'utils',name_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report.create_report(extension = \"html\", keep_code = False, notebookname = \"07_pollution_abatement_equation.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
