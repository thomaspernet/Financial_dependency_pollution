{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# NOTEBOOK NAME FROM CODA TASK\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'XX.csv'\n",
    "region = ''\n",
    "bucket = ''\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = ''\n",
    "table = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "- Filename: XX\n",
    "- S3: https://s3.console.aws.amazon.com/s3/buckets/XX/DATA/TRANSFORMED/?region=eu-west-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = True\n",
    "if download_data:\n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = 'XX', verbose = False)\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM {}.{}\n",
    "    \"\"\".format(db, table)\n",
    "    df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename='XX',  # Add filename to print dataframe\n",
    "        destination_key='DATA/TRANSFORMED',  # Add destination key if need to copy output\n",
    "        dtype = dtypes\n",
    "    )\n",
    "            )\n",
    "    s3.download_file(\n",
    "        key = 'DATA/TRANSFORMED/XX.csv',\n",
    "    path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalogue/temporary_local_data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Models to estimate\n",
    "\n",
    "The model to estimate is: \n",
    "\n",
    "## Fixed Effect\n",
    "\n",
    "TABLE FIXED EFFECT\n",
    "\n",
    "\n",
    "- FE NAME: `FE NAME IN TALBE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "import function.latex_beautify as lb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "path = \"function/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "path = '../../../00_Data_catalogue/temporary_local_data/XX.csv'\n",
    "df_final <- read_csv(path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "mutate(regime = relevel(XX, ref='XX'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 1:XXX\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Write your equation}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "* Column 1: XXX\n",
    "    * FE: \n",
    "        - fe 1: `XX`\n",
    "        - fe 2: `XX`\n",
    "        - fe 3: `XX`\n",
    "* Column 2: XXX\n",
    "    * FE: \n",
    "        - fe 1: `XX`\n",
    "        - fe 2: `XX`\n",
    "        - fe 3: `XX`\n",
    "* Column 3: XXX\n",
    "    * FE: \n",
    "        - fe 1: `XX`\n",
    "        - fe 2: `XX`\n",
    "        - fe 3: `XX`\n",
    "* Column 4: XXX\n",
    "    * FE: \n",
    "        - fe 1: `XX`\n",
    "        - fe 2: `XX`\n",
    "        - fe 3: `XX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "t_0 <- felm(YYY ~XXX\n",
    "            | FE|0 | CLUSTER, df_final %>% filter(XXX == 'YYY'),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_0 <- felm(YYY ~XXX\n",
    "            | FE|0 | CLUSTER, df_final %>% filter(XXX != 'YYY'),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(kYYY ~XXX\n",
    "            | FE|0 | CLUSTER, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_3 <- felm(kYYY ~XXX\n",
    "            | FE|0 | CLUSTER, df_final,\n",
    "            exactDOF = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.remove(\"Tables/table_0.txt\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(\"Tables/table_0.tex\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(\"Tables/table_0.pdf\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "dep <- \"Dependent variable: YYYY\"\n",
    "fe1 <- list(\n",
    "    c(\"XXXXX\", \"Yes\", \"Yes\", \"No\", \"No\"),\n",
    "    \n",
    "    c(\"XXXXX\", \"Yes\", \"Yes\", \"No\", \"No\"),\n",
    "    \n",
    "    c(\"XXXXX\",\"Yes\", \"Yes\", \"Yes\", \"No\"),\n",
    "    \n",
    "    c(\"XXXXX\",\"No\", \"No\", \"Yes\", \"Yes\"),\n",
    "    \n",
    "    c(\"XXXXX\",\"No\", \"No\", \"Yes\", \"Yes\"),\n",
    "    \n",
    "    c(\"XXXXX\", \"No\", \"No\", \"No\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3\n",
    "),\n",
    "    title=\"TITLE\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=\"Tables/table_0.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"This table estimates eq(3). \" \\\n",
    "\"Heteroskedasticity-robust standard errors\" \\\n",
    "\"clustered at the product level appear inparentheses.\"\\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "multicolumn ={\n",
    "    'Eligible': 1,\n",
    "    'Non-Eligible': 1,\n",
    "    'All': 1,\n",
    "    'All benchmark': 1,\n",
    "}\n",
    "multi_lines_dep = ''\n",
    "#new_r = ['& Eligible', 'Non-Eligible', 'All', 'All benchmark']\n",
    "lb.beautify(table_number = 0,\n",
    "            #multi_lines_dep = None,\n",
    "            multi_lines_dep = multi_lines_dep,\n",
    "            new_row= False,\n",
    "            multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report(extension = \"html\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.23.1"
  },
  "sos": {
   "kernels": [
    [
     "Python 3",
     "python3",
     "python3",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
