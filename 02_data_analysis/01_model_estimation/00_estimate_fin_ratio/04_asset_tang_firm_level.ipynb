{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "\n",
    "Estimate asset_tangibility as a function of  financial ratio and others (estimate table 6 Andersen, etc) \n",
    "\n",
    "# Business needs \n",
    "\n",
    "Estimate asset_tangibility as a function of  financial ratio, credit constraint, city policy mandate, tcz, spz, capital, employment, sales, output (Replicate table 6 Andersen Determinants of firm-level asset tangibility., Add proxy to firm size like output, sales, employment separately, add more parameters to the model specific to China like policy mandate, tcz, spz) \n",
    "\n",
    "## Description\n",
    "### Objective \n",
    "\n",
    "Test the coefficient sign and significant of the main variable\n",
    "\n",
    "### Tables\n",
    "\n",
    "1. Table 1: Baseline Estimate, determinants of firm-level asset tangibility.\n",
    "  1. asset_tangibility and financial ratio, credit constraint, city policy mandate, tcz, spz, capital, employment, sales, output\n",
    "\n",
    "**Cautious**\n",
    "Make sure no empty rows, otherwise it will be filtered out in the estimate\n",
    "\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: bnj64hblu96864v\n",
    "- Epic: Models\n",
    "- US: Firm level estimate\n",
    "- Task tag: #analytics, #firm-level, #tangible-asset, #andersen\n",
    "- Analytics reports: \n",
    "\n",
    "# Input Cloud Storage\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name** \n",
    "\n",
    "- https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/02_transform_tables/06_asif_financial_ratio_firm_baseline.md\n",
    "\n",
    "**Github**\n",
    "\n",
    "- DATA/ECON/FIRM_SURVEY/ASIF_CHINA/TRANSFORMED/FINANCIAL_RATIO/FIRM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-3'\n",
    "bucket = 'datalake-datascience'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'firms_survey'\n",
    "table = 'asif_financial_ratio_baseline_firm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = False\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalogue/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM {}.{}\n",
    "    \"\"\".format(db, table)\n",
    "    df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename=filename,  # Add filename to print dataframe\n",
    "        destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        dtype = dtypes\n",
    "    )\n",
    "            )\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = True\n",
    "\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "        data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename = [\n",
    "        ### control variables\n",
    "        {\n",
    "        'old':'output',\n",
    "        'new':'\\\\text{output}_{cit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'employment',\n",
    "        'new':'\\\\text{employment}_{cit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'capital',\n",
    "        'new':'\\\\text{capital}_{cit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'sales',\n",
    "        'new':'\\\\text{sales}_{cit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'total\\_asset',\n",
    "        'new':'\\\\text{total asset}_{cit}'\n",
    "        },\n",
    "        ####\n",
    "        {\n",
    "        'old':'asset\\_tangibility\\_fcit',\n",
    "        'new':'\\\\text{asset tangibility}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cash\\_over\\_totasset\\_fcit',\n",
    "        'new':'\\\\text{cash over asset}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'sales\\_assets\\_andersen\\_fcit',\n",
    "        'new':'\\\\text{sales over assets}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'return\\_on\\_asset\\_fcit',\n",
    "        'new':'\\\\text{return on asset}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'liabilities\\_assets\\_fcit',\n",
    "        'new':'\\\\text{liabilities assets}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'quick\\_ratio\\_fcit',\n",
    "        'new':'\\\\text{quick ratio}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'current\\_ratio\\_fcit',\n",
    "        'new':'\\\\text{current ratio}_{fcit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'d\\_credit\\_constraintBELOW',\n",
    "        'new':'\\\\text{Fin dep}_{i}'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import function.latex_beautify as lb\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "path = \"function/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "mutate(\n",
    "    period = relevel(as.factor(period), ref='FALSE'),\n",
    "    #asset_tangibility_fcit = asset_tangibility_fcit /1000000000,\n",
    "    #cash_over_totasset_fcit = cash_over_totasset_fcit /100000,\n",
    "    #liabilities_assets_fcit = liabilities_assets_fcit /100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 1. Table 1: Baseline Estimate, determinants of firm-level asset tangibility.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { Asset Tangibility }_{f i t}=\\delta_{7} \\text { Current Ratio }_{f i t-1}+\\delta_{8} \\text { Cash/Assets }_{f i t-1}+\\delta_{9} \\text { Liabilities/Assets }_{f i t-1}+\\Lambda_{\\text {fit }}^{\\prime} X+\\vartheta_{i t}+u_{\\text {fit }}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "* Column 1: Baseline\n",
    "    * FE: \n",
    "        - fe 1: `firm`\n",
    "* Column 2: Add control\n",
    "    * FE: \n",
    "        - fe 1: `firm`\n",
    "* Column 3: Test credit constraint interaction\n",
    "    * FE: \n",
    "        - fe 1: `firm`\n",
    "        \n",
    "![](https://drive.google.com/uc?export=view&id=12uyrdOY5hskcWeH9ZlU8y4MazgEeEHWK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.tex', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t_0 <- felm(log(asset_tangibility_fcit) ~ log(current_ratio_fcit) +\n",
    "            log(cash_over_totasset_fcit) +\n",
    "            log(liabilities_assets_fcit)\n",
    "            | firm|0 | firm, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_1 <- felm(log(asset_tangibility_fcit) ~ log(current_ratio_fcit) +\n",
    "            log(cash_over_totasset_fcit) + \n",
    "            log(liabilities_assets_fcit) +\n",
    "            log(sales_assets_andersen_fcit) \n",
    "            | firm|0 | firm,df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(log(asset_tangibility_fcit) ~ log(current_ratio_fcit) +\n",
    "            log(cash_over_totasset_fcit) + \n",
    "            log(liabilities_assets_fcit) +\n",
    "            log(current_ratio_fcit) * d_credit_constraint  + \n",
    "            log(cash_over_totasset_fcit) * d_credit_constraint + \n",
    "            log(liabilities_assets_fcit) * d_credit_constraint\n",
    "            | firm|0 | firm, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "### more controls\n",
    "t_3 <- felm(log(asset_tangibility_fcit) ~ log(current_ratio_fcit) +\n",
    "            log(cash_over_totasset_fcit) + \n",
    "            log(liabilities_assets_fcit) +\n",
    "            log(output)\n",
    "            | firm |0 | firm,df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_4 <- felm(log(asset_tangibility_fcit) ~ log(current_ratio_fcit) +\n",
    "            log(cash_over_totasset_fcit) +\n",
    "            log(liabilities_assets_fcit) +\n",
    "            log(sales_assets_andersen_fcit) +\n",
    "            log(output)\n",
    "            | firm|0 | firm, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_5 <- felm(log(asset_tangibility_fcit) ~ log(current_ratio_fcit) +\n",
    "            log(cash_over_totasset_fcit) +\n",
    "            log(liabilities_assets_fcit) +\n",
    "            log(current_ratio_fcit) * d_credit_constraint  + \n",
    "            log(cash_over_totasset_fcit) * d_credit_constraint + \n",
    "            log(liabilities_assets_fcit) * d_credit_constraint + \n",
    "            log(output)\n",
    "            | firm|0 | firm,df_final,\n",
    "            exactDOF = TRUE)\n",
    "            \n",
    "dep <- \"Dependent variable: Asset tangilibility\"\n",
    "fe1 <- list(\n",
    "    c(\"firm\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")#,\n",
    "    #c(\"year\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"Baseline Estimate, determinants of firm-level asset tangibility\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"This table estimates eq(3). \" \\\n",
    "\"Heteroskedasticity-robust standard errors\" \\\n",
    "\"clustered at the product level appear inparentheses.\"\\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "#multicolumn ={\n",
    "#    'Eligible': 2,\n",
    "#    'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "#new_r = ['& test1', 'test2']\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 200,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.tex', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False, notebookname = None):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            notebookname = notebookname  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = False, notebookname = \"04_asset_tang_firm_level.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.26.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
