{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Transform (creating time break variables) financial ration data and merging pollution tables to S3\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "## Business needs \n",
    "\n",
    "Transform (creating time-break variables and fixed effect) asif_financial_ratio data and merging pollution, industry and city mandate tables using Athena and save output to S3 + Glue. \n",
    "\n",
    "## Description\n",
    "\n",
    "**Objective**\n",
    "\n",
    "Construct the time-break and fixed effect variables\n",
    "\n",
    "**Construction variables**\n",
    "\n",
    "* time-break: If year prior to 2006, then False else True\n",
    "* Fixed effect:\n",
    "  * city-industry: FE_c_i\n",
    "  * time-industry: FE_t_i\n",
    "  * city-time: FE_c_t\n",
    "\n",
    "**Steps**\n",
    "\n",
    "We will clean the table by doing the following steps:\n",
    "\n",
    "1. merge tables asif_city_industry_financial_ratio  with\n",
    "  1. china_city_sector_pollution \n",
    "  2. china_city_tcz_spz\n",
    "  3. china_city_reduction_mandate\n",
    "  4. china_code_normalised\n",
    "  5. ind_cic_2_name\n",
    "\n",
    "**Cautious**\n",
    "\n",
    "* Make sure there is no duplicates\n",
    "\n",
    "\n",
    "Target\n",
    "* The file is saved in S3: \n",
    "  * bucket: datalake-datascience \n",
    "  * path: DATA/ENVIRONMENT/CHINA/FYP/FINANCIAL_CONTRAINT/PAPER_FYP_FINANCE_POL/BASELINE \n",
    "* Glue data catalog should be updated\n",
    "  * database: environment \n",
    "  * table prefix: fin_dep_pollution \n",
    "    * table name (prefix + last folder S3 path): fin_dep_pollution_baseline \n",
    "* Analytics\n",
    "  * HTML:  ANALYTICS/HTML_OUTPUT/FIN_DEP_POLLUTION_BASELINE \n",
    "  * Notebook:  ANALYTICS/OUTPUT/FIN_DEP_POLLUTION_BASELINE \n",
    "\n",
    "# Metadata\n",
    "\n",
    "* Key: jfl55vdtx66109y\n",
    "* Parent key (for update parent):  \n",
    "* Notebook US Parent (i.e the one to update): \n",
    "* https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/02_transform_tables/01_fin_dep_pol_baseline.md\n",
    "* Epic: Epic 2\n",
    "* US: US 2\n",
    "* Date Begin: 11/24/2020\n",
    "* Duration Task: 1\n",
    "* Description: Transform (creating time-break variables and fixed effect) asif_financial_ratio data and merging pollution, industry and city mandate tables using Athena and save output to S3 + Glue. \n",
    "* Step type: Transform table\n",
    "* Status: Active\n",
    "* Source URL: US 02 Baseline\n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://468786073381.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 8\n",
    "* Task tag: #baseline-table,#financial-ratio,#policy,#pollution\n",
    "* Toggl Tag: #data-transformation\n",
    "* current nb commits: 0\n",
    "* Meetings:  \n",
    "* Presentation:  \n",
    "* Email Information:  \n",
    "  * thread: Number of threads: 0(Default 0, to avoid display email)\n",
    "  *  \n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name: \n",
    "* asif_city_industry_financial_ratio\n",
    "* china_city_reduction_mandate\n",
    "* china_city_sector_pollution \n",
    "* china_city_tcz_spz\n",
    "* china_code_normalised\n",
    "* ind_cic_2_name\n",
    "* Github: \n",
    "  * https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/02_transform_tables/00_asif_financial_ratio.md\n",
    "  * https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/00_download_data_from/CITY_REDUCTION_MANDATE/city_reduction_mandate.py\n",
    "  * https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/00_download_data_from/CITY_SECTOR_POLLUTION/city_sector_pollution.py\n",
    "  * https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/00_download_data_from/TCZ_SPZ/tcz_spz_policy.py\n",
    "  * https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/00_download_data_from/CITY_CODE_CORRESPONDANCE/city_code_correspondance.py\n",
    "  * https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/00_download_data_from/CIC_NAME/cic_industry_name.py\n",
    "\n",
    "# Destination Output/Delivery\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* S3\n",
    "* Athena\n",
    "* Name:\n",
    "* DATA/ENVIRONMENT/CHINA/FYP/FINANCIAL_CONTRAINT/PAPER_FYP_FINANCE_POL/BASELINE\n",
    "* fin_dep_pollution_baseline\n",
    "* GitHub:\n",
    "* https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/01_data_preprocessing/02_transform_tables/01_fin_dep_pol_baseline.md\n",
    "* URL: \n",
    "  * datalake-datascience/DATA/ENVIRONMENT/CHINA/FYP/FINANCIAL_CONTRAINT/PAPER_FYP_FINANCE_POL/BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil, json\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-3'\n",
    "bucket = 'datalake-datascience'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = True) \n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare query \n",
    "\n",
    "Write query and save the CSV back in the S3 bucket `datalake-datascience` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Load the pollution data: china_city_sector_pollution\n",
    "2. Merge with:\n",
    "    - asif_city_industry_financial_ratio\n",
    "    - china_city_reduction_mandate\n",
    "    - china_city_tcz_spz\n",
    "    - china_code_normalised\n",
    "    - ind_cic_2_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatabaseName = 'environment'\n",
    "s3_output_example = 'SQL_OUTPUT_ATHENA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>prov2013</th>\n",
       "      <th>provinces</th>\n",
       "      <th>citycode</th>\n",
       "      <th>citycn</th>\n",
       "      <th>cityen</th>\n",
       "      <th>indus_code</th>\n",
       "      <th>ind2</th>\n",
       "      <th>ttoutput</th>\n",
       "      <th>twaste_water</th>\n",
       "      <th>tcod</th>\n",
       "      <th>tammonia_nitrogen</th>\n",
       "      <th>twaste_gas</th>\n",
       "      <th>tso2</th>\n",
       "      <th>tnox</th>\n",
       "      <th>tsmoke_dust</th>\n",
       "      <th>tsoot</th>\n",
       "      <th>lower_location</th>\n",
       "      <th>larger_location</th>\n",
       "      <th>coastal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>2110</td>\n",
       "      <td>21</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540</td>\n",
       "      <td>8640</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>2720</td>\n",
       "      <td>27</td>\n",
       "      <td>346125.0</td>\n",
       "      <td>23814734</td>\n",
       "      <td>13626894.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251746</td>\n",
       "      <td>119819</td>\n",
       "      <td>0</td>\n",
       "      <td>135020</td>\n",
       "      <td>40000</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>2631</td>\n",
       "      <td>26</td>\n",
       "      <td>35206.0</td>\n",
       "      <td>6857995</td>\n",
       "      <td>1313520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>34800</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>2600</td>\n",
       "      <td>26</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>3541</td>\n",
       "      <td>35</td>\n",
       "      <td>11184.4</td>\n",
       "      <td>216750</td>\n",
       "      <td>32384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3174</td>\n",
       "      <td>79844</td>\n",
       "      <td>0</td>\n",
       "      <td>24122</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>3124</td>\n",
       "      <td>31</td>\n",
       "      <td>449.0</td>\n",
       "      <td>49600</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>19360</td>\n",
       "      <td>0</td>\n",
       "      <td>3630</td>\n",
       "      <td>3600</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>2651</td>\n",
       "      <td>26</td>\n",
       "      <td>22652.0</td>\n",
       "      <td>3178348</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72792</td>\n",
       "      <td>447270</td>\n",
       "      <td>0</td>\n",
       "      <td>199888</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>3511</td>\n",
       "      <td>35</td>\n",
       "      <td>190.0</td>\n",
       "      <td>400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>2621</td>\n",
       "      <td>26</td>\n",
       "      <td>124696.4</td>\n",
       "      <td>26307242</td>\n",
       "      <td>12107578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493985</td>\n",
       "      <td>6454855</td>\n",
       "      <td>0</td>\n",
       "      <td>4783895</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>4160</td>\n",
       "      <td>41</td>\n",
       "      <td>79863.0</td>\n",
       "      <td>1025573</td>\n",
       "      <td>124382.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31790</td>\n",
       "      <td>267253</td>\n",
       "      <td>0</td>\n",
       "      <td>141798</td>\n",
       "      <td>0</td>\n",
       "      <td>Coastal</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year prov2013 provinces  citycode citycn        cityen  indus_code  ind2  \\\n",
       "0  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        2110    21   \n",
       "1  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        2720    27   \n",
       "2  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        2631    26   \n",
       "3  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        2600    26   \n",
       "4  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        3541    35   \n",
       "5  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        3124    31   \n",
       "6  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        2651    26   \n",
       "7  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        3511    35   \n",
       "8  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        2621    26   \n",
       "9  1998      河北省     Hebei      1301    石家庄  Shijiazhuang        4160    41   \n",
       "\n",
       "   ttoutput  twaste_water        tcod  tammonia_nitrogen  twaste_gas     tso2  \\\n",
       "0     800.0           800         0.0                0.0         540     8640   \n",
       "1  346125.0      23814734  13626894.0                0.0      251746   119819   \n",
       "2   35206.0       6857995   1313520.0                0.0        1991    19000   \n",
       "3    4400.0          2000     86400.0                0.0         919   192000   \n",
       "4   11184.4        216750     32384.0                0.0        3174    79844   \n",
       "5     449.0         49600     20000.0                0.0        1110    19360   \n",
       "6   22652.0       3178348    560076.0                0.0       72792   447270   \n",
       "7     190.0           400         0.0                0.0          10       60   \n",
       "8  124696.4      26307242  12107578.0                0.0      493985  6454855   \n",
       "9   79863.0       1025573    124382.0                0.0       31790   267253   \n",
       "\n",
       "   tnox  tsmoke_dust  tsoot lower_location larger_location coastal  \n",
       "0     0         3600      0        Coastal         Eastern     Yes  \n",
       "1     0       135020  40000        Coastal         Eastern     Yes  \n",
       "2     0        34800      0        Coastal         Eastern     Yes  \n",
       "3     0        12000      0        Coastal         Eastern     Yes  \n",
       "4     0        24122      0        Coastal         Eastern     Yes  \n",
       "5     0         3630   3600        Coastal         Eastern     Yes  \n",
       "6     0       199888      0        Coastal         Eastern     Yes  \n",
       "7     0          300      0        Coastal         Eastern     Yes  \n",
       "8     0      4783895      0        Coastal         Eastern     Yes  \n",
       "9     0       141798      0        Coastal         Eastern     Yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT *\n",
    "FROM environment.china_city_sector_pollution\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_1'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of observation in `china_city_sector_pollution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CNT\n",
       "0  189475"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT COUNT(*) AS CNT\n",
    "FROM environment.china_city_sector_pollution\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'count_1'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citycode</th>\n",
       "      <th>cic</th>\n",
       "      <th>year</th>\n",
       "      <th>working_capital_cit</th>\n",
       "      <th>working_capital_ci</th>\n",
       "      <th>working_capital_i</th>\n",
       "      <th>asset_tangibility_cit</th>\n",
       "      <th>asset_tangibility_ci</th>\n",
       "      <th>asset_tangibility_i</th>\n",
       "      <th>current_ratio_cit</th>\n",
       "      <th>current_ratio_ci</th>\n",
       "      <th>current_ratio_i</th>\n",
       "      <th>cash_assets_cit</th>\n",
       "      <th>cash_assets_ci</th>\n",
       "      <th>cash_assets_i</th>\n",
       "      <th>liabilities_assets_cit</th>\n",
       "      <th>liabilities_assets_ci</th>\n",
       "      <th>liabilities_assets_i</th>\n",
       "      <th>return_on_asset_cit</th>\n",
       "      <th>return_on_asset_ci</th>\n",
       "      <th>return_on_asset_i</th>\n",
       "      <th>sales_assets_cit</th>\n",
       "      <th>sales_assets_ci</th>\n",
       "      <th>sales_assets_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4309</td>\n",
       "      <td>2490</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3178</td>\n",
       "      <td>3301.00</td>\n",
       "      <td>9948.428571</td>\n",
       "      <td>2.45018</td>\n",
       "      <td>2.33334</td>\n",
       "      <td>2.00324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36335</td>\n",
       "      <td>0.36335</td>\n",
       "      <td>0.51886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.15760</td>\n",
       "      <td>-23.39583</td>\n",
       "      <td>-5.95101</td>\n",
       "      <td>7.84145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4309</td>\n",
       "      <td>2490</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152</td>\n",
       "      <td>3301.00</td>\n",
       "      <td>9948.428571</td>\n",
       "      <td>3.05155</td>\n",
       "      <td>2.33334</td>\n",
       "      <td>2.00324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36335</td>\n",
       "      <td>0.51886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.15760</td>\n",
       "      <td>-18.39053</td>\n",
       "      <td>-5.95101</td>\n",
       "      <td>7.84145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4402</td>\n",
       "      <td>1312</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28006</td>\n",
       "      <td>27098.00</td>\n",
       "      <td>54691.709273</td>\n",
       "      <td>0.51531</td>\n",
       "      <td>0.62995</td>\n",
       "      <td>1.27969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>0.84745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.00277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.23441</td>\n",
       "      <td>36.70418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4402</td>\n",
       "      <td>1312</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28027</td>\n",
       "      <td>27098.00</td>\n",
       "      <td>54691.709273</td>\n",
       "      <td>0.52982</td>\n",
       "      <td>0.62995</td>\n",
       "      <td>1.27969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>0.84745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.00277</td>\n",
       "      <td>-5.59066</td>\n",
       "      <td>-0.23441</td>\n",
       "      <td>36.70418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4402</td>\n",
       "      <td>1312</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29500</td>\n",
       "      <td>27098.00</td>\n",
       "      <td>54691.709273</td>\n",
       "      <td>0.41277</td>\n",
       "      <td>0.62995</td>\n",
       "      <td>1.27969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>0.84745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.00277</td>\n",
       "      <td>-4.03443</td>\n",
       "      <td>-0.23441</td>\n",
       "      <td>36.70418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4402</td>\n",
       "      <td>1312</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22859</td>\n",
       "      <td>27098.00</td>\n",
       "      <td>54691.709273</td>\n",
       "      <td>1.06191</td>\n",
       "      <td>0.62995</td>\n",
       "      <td>1.27969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>0.84745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.00277</td>\n",
       "      <td>8.92187</td>\n",
       "      <td>-0.23441</td>\n",
       "      <td>36.70418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4402</td>\n",
       "      <td>2040</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8877.25</td>\n",
       "      <td>14804.161224</td>\n",
       "      <td>1550</td>\n",
       "      <td>1125.25</td>\n",
       "      <td>7989.767981</td>\n",
       "      <td>3.08824</td>\n",
       "      <td>2.93294</td>\n",
       "      <td>2.21921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.34685</td>\n",
       "      <td>-1.49301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34687</td>\n",
       "      <td>0.44941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.18496</td>\n",
       "      <td>7.94262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44.60324</td>\n",
       "      <td>1.30116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4402</td>\n",
       "      <td>2040</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8877.25</td>\n",
       "      <td>14804.161224</td>\n",
       "      <td>0</td>\n",
       "      <td>1125.25</td>\n",
       "      <td>7989.767981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.93294</td>\n",
       "      <td>2.21921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.34685</td>\n",
       "      <td>-1.49301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34687</td>\n",
       "      <td>0.44941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.18496</td>\n",
       "      <td>7.94262</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-44.60324</td>\n",
       "      <td>1.30116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4402</td>\n",
       "      <td>2040</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8877.25</td>\n",
       "      <td>14804.161224</td>\n",
       "      <td>0</td>\n",
       "      <td>1125.25</td>\n",
       "      <td>7989.767981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.93294</td>\n",
       "      <td>2.21921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.34685</td>\n",
       "      <td>-1.49301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34687</td>\n",
       "      <td>0.44941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.18496</td>\n",
       "      <td>7.94262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44.60324</td>\n",
       "      <td>1.30116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4402</td>\n",
       "      <td>2040</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8877.25</td>\n",
       "      <td>14804.161224</td>\n",
       "      <td>2951</td>\n",
       "      <td>1125.25</td>\n",
       "      <td>7989.767981</td>\n",
       "      <td>3.45554</td>\n",
       "      <td>2.93294</td>\n",
       "      <td>2.21921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.34685</td>\n",
       "      <td>-1.49301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34687</td>\n",
       "      <td>0.44941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.18496</td>\n",
       "      <td>7.94262</td>\n",
       "      <td>6.91108</td>\n",
       "      <td>-44.60324</td>\n",
       "      <td>1.30116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citycode   cic  year  working_capital_cit  working_capital_ci  \\\n",
       "0      4309  2490  2000                  NaN                 NaN   \n",
       "1      4309  2490  2001                  NaN                 NaN   \n",
       "2      4402  1312  1998                  NaN                 NaN   \n",
       "3      4402  1312  1999                  NaN                 NaN   \n",
       "4      4402  1312  2000                  NaN                 NaN   \n",
       "5      4402  1312  2001                  NaN                 NaN   \n",
       "6      4402  2040  1998                  NaN             8877.25   \n",
       "7      4402  2040  1999                  NaN             8877.25   \n",
       "8      4402  2040  2000                  NaN             8877.25   \n",
       "9      4402  2040  2002                  NaN             8877.25   \n",
       "\n",
       "   working_capital_i  asset_tangibility_cit  asset_tangibility_ci  \\\n",
       "0                NaN                   3178               3301.00   \n",
       "1                NaN                   3152               3301.00   \n",
       "2                NaN                  28006              27098.00   \n",
       "3                NaN                  28027              27098.00   \n",
       "4                NaN                  29500              27098.00   \n",
       "5                NaN                  22859              27098.00   \n",
       "6       14804.161224                   1550               1125.25   \n",
       "7       14804.161224                      0               1125.25   \n",
       "8       14804.161224                      0               1125.25   \n",
       "9       14804.161224                   2951               1125.25   \n",
       "\n",
       "   asset_tangibility_i  current_ratio_cit  current_ratio_ci  current_ratio_i  \\\n",
       "0          9948.428571            2.45018           2.33334          2.00324   \n",
       "1          9948.428571            3.05155           2.33334          2.00324   \n",
       "2         54691.709273            0.51531           0.62995          1.27969   \n",
       "3         54691.709273            0.52982           0.62995          1.27969   \n",
       "4         54691.709273            0.41277           0.62995          1.27969   \n",
       "5         54691.709273            1.06191           0.62995          1.27969   \n",
       "6          7989.767981            3.08824           2.93294          2.21921   \n",
       "7          7989.767981                NaN           2.93294          2.21921   \n",
       "8          7989.767981                NaN           2.93294          2.21921   \n",
       "9          7989.767981            3.45554           2.93294          2.21921   \n",
       "\n",
       "   cash_assets_cit  cash_assets_ci  cash_assets_i  liabilities_assets_cit  \\\n",
       "0              NaN             NaN            NaN                 0.36335   \n",
       "1              NaN             NaN            NaN                     NaN   \n",
       "2              NaN             NaN            NaN                     NaN   \n",
       "3              NaN             NaN            NaN                     NaN   \n",
       "4              NaN             NaN            NaN                 0.90388   \n",
       "5              NaN             NaN            NaN                     NaN   \n",
       "6              NaN        -0.34685       -1.49301                     NaN   \n",
       "7              NaN        -0.34685       -1.49301                     NaN   \n",
       "8              NaN        -0.34685       -1.49301                     NaN   \n",
       "9              NaN        -0.34685       -1.49301                     NaN   \n",
       "\n",
       "   liabilities_assets_ci  liabilities_assets_i  return_on_asset_cit  \\\n",
       "0                0.36335               0.51886                  NaN   \n",
       "1                0.36335               0.51886                  NaN   \n",
       "2                0.90388               0.84745                  NaN   \n",
       "3                0.90388               0.84745                  NaN   \n",
       "4                0.90388               0.84745                  NaN   \n",
       "5                0.90388               0.84745                  NaN   \n",
       "6                0.34687               0.44941                  NaN   \n",
       "7                0.34687               0.44941                  NaN   \n",
       "8                0.34687               0.44941                  NaN   \n",
       "9                0.34687               0.44941                  NaN   \n",
       "\n",
       "   return_on_asset_ci  return_on_asset_i  sales_assets_cit  sales_assets_ci  \\\n",
       "0                 NaN           -0.15760         -23.39583         -5.95101   \n",
       "1                 NaN           -0.15760         -18.39053         -5.95101   \n",
       "2                 NaN           -0.00277               NaN         -0.23441   \n",
       "3                 NaN           -0.00277          -5.59066         -0.23441   \n",
       "4                 NaN           -0.00277          -4.03443         -0.23441   \n",
       "5                 NaN           -0.00277           8.92187         -0.23441   \n",
       "6             9.18496            7.94262               NaN        -44.60324   \n",
       "7             9.18496            7.94262           0.00000        -44.60324   \n",
       "8             9.18496            7.94262               NaN        -44.60324   \n",
       "9             9.18496            7.94262           6.91108        -44.60324   \n",
       "\n",
       "   sales_assets_i  \n",
       "0         7.84145  \n",
       "1         7.84145  \n",
       "2        36.70418  \n",
       "3        36.70418  \n",
       "4        36.70418  \n",
       "5        36.70418  \n",
       "6         1.30116  \n",
       "7         1.30116  \n",
       "8         1.30116  \n",
       "9         1.30116  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT *\n",
    "FROM firms_survey.asif_city_industry_financial_ratio\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_2'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citycn</th>\n",
       "      <th>cityen</th>\n",
       "      <th>prov2013</th>\n",
       "      <th>so2_05_city_reconstructed</th>\n",
       "      <th>so2_obj_2010</th>\n",
       "      <th>tso2_mandate_c</th>\n",
       "      <th>so2_perc_reduction_c</th>\n",
       "      <th>ttoutput</th>\n",
       "      <th>in_10_000_tonnes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上海</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>上海市</td>\n",
       "      <td>5.121932</td>\n",
       "      <td>3.794024</td>\n",
       "      <td>1.327908</td>\n",
       "      <td>0.26</td>\n",
       "      <td>230979744.0</td>\n",
       "      <td>1.327908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>昆明</td>\n",
       "      <td>Kunming</td>\n",
       "      <td>云南省</td>\n",
       "      <td>2.237456</td>\n",
       "      <td>2.147444</td>\n",
       "      <td>0.090013</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6370188.0</td>\n",
       "      <td>0.900126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>曲靖</td>\n",
       "      <td>Qujing</td>\n",
       "      <td>云南省</td>\n",
       "      <td>1.223688</td>\n",
       "      <td>1.174459</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1871252.8</td>\n",
       "      <td>0.492288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>玉溪</td>\n",
       "      <td>Yuxi</td>\n",
       "      <td>云南省</td>\n",
       "      <td>0.770952</td>\n",
       "      <td>0.739937</td>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2821705.5</td>\n",
       "      <td>0.310153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>思茅</td>\n",
       "      <td>Simao</td>\n",
       "      <td>云南省</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.239366</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>240283.8</td>\n",
       "      <td>0.100333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>保山</td>\n",
       "      <td>Baoshan</td>\n",
       "      <td>云南省</td>\n",
       "      <td>0.225593</td>\n",
       "      <td>0.216518</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>271308.6</td>\n",
       "      <td>0.090756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>昭通</td>\n",
       "      <td>Zhaotong</td>\n",
       "      <td>云南省</td>\n",
       "      <td>0.172856</td>\n",
       "      <td>0.165902</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.00</td>\n",
       "      <td>388868.7</td>\n",
       "      <td>0.069540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>丽江</td>\n",
       "      <td>Lijiang</td>\n",
       "      <td>云南省</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.093926</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57121.5</td>\n",
       "      <td>0.039370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>临沧</td>\n",
       "      <td>Lincang</td>\n",
       "      <td>云南省</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.092088</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.00</td>\n",
       "      <td>162455.5</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>包头</td>\n",
       "      <td>Baotou</td>\n",
       "      <td>内蒙古自治区</td>\n",
       "      <td>4.658621</td>\n",
       "      <td>4.479443</td>\n",
       "      <td>0.179178</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4747308.5</td>\n",
       "      <td>1.791777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  citycn    cityen prov2013  so2_05_city_reconstructed  so2_obj_2010  \\\n",
       "0     上海  Shanghai      上海市                   5.121932      3.794024   \n",
       "1     昆明   Kunming      云南省                   2.237456      2.147444   \n",
       "2     曲靖    Qujing      云南省                   1.223688      1.174459   \n",
       "3     玉溪      Yuxi      云南省                   0.770952      0.739937   \n",
       "4     思茅     Simao      云南省                   0.249400      0.239366   \n",
       "5     保山   Baoshan      云南省                   0.225593      0.216518   \n",
       "6     昭通  Zhaotong      云南省                   0.172856      0.165902   \n",
       "7     丽江   Lijiang      云南省                   0.097863      0.093926   \n",
       "8     临沧   Lincang      云南省                   0.095948      0.092088   \n",
       "9     包头    Baotou   内蒙古自治区                   4.658621      4.479443   \n",
       "\n",
       "   tso2_mandate_c  so2_perc_reduction_c     ttoutput  in_10_000_tonnes  \n",
       "0        1.327908                  0.26  230979744.0          1.327908  \n",
       "1        0.090013                  0.02    6370188.0          0.900126  \n",
       "2        0.049229                  0.01    1871252.8          0.492288  \n",
       "3        0.031015                  0.01    2821705.5          0.310153  \n",
       "4        0.010033                  0.00     240283.8          0.100333  \n",
       "5        0.009076                  0.00     271308.6          0.090756  \n",
       "6        0.006954                  0.00     388868.7          0.069540  \n",
       "7        0.003937                  0.00      57121.5          0.039370  \n",
       "8        0.003860                  0.00     162455.5          0.038600  \n",
       "9        0.179178                  0.01    4747308.5          1.791777  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT *\n",
    "FROM policy.china_city_reduction_mandate\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_3'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of observation in `china_city_reduction_mandate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT\n",
       "0  285"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT COUNT(*) AS CNT\n",
    "FROM policy.china_city_reduction_mandate\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'count_2'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>geocode4_corr</th>\n",
       "      <th>tcz</th>\n",
       "      <th>spz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tianjin</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Tangshan</td>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Qinhuangdao</td>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Handan</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Xingtai</td>\n",
       "      <td>1305</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Baoding</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Zhangjiakou</td>\n",
       "      <td>1307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>Chengde</td>\n",
       "      <td>1308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province          city  geocode4_corr  tcz  spz\n",
       "0  Beijing       Beijing           1101    1    1\n",
       "1  Tianjin       Tianjin           1201    1    1\n",
       "2    Hebei  Shijiazhuang           1301    1    1\n",
       "3    Hebei      Tangshan           1302    1    0\n",
       "4    Hebei   Qinhuangdao           1303    0    1\n",
       "5    Hebei        Handan           1304    1    0\n",
       "6    Hebei       Xingtai           1305    1    0\n",
       "7    Hebei       Baoding           1306    1    1\n",
       "8    Hebei   Zhangjiakou           1307    1    0\n",
       "9    Hebei       Chengde           1308    1    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT *\n",
    "FROM policy.china_city_tcz_spz\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_4'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extra_code</th>\n",
       "      <th>geocode4_corr</th>\n",
       "      <th>citycn</th>\n",
       "      <th>cityen</th>\n",
       "      <th>citycn_correct</th>\n",
       "      <th>cityen_correct</th>\n",
       "      <th>province_cn</th>\n",
       "      <th>province_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100</td>\n",
       "      <td>1101</td>\n",
       "      <td>北京</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>北京</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>北京市</td>\n",
       "      <td>Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101</td>\n",
       "      <td>1101</td>\n",
       "      <td>北京</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>北京</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>北京市</td>\n",
       "      <td>Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102</td>\n",
       "      <td>1101</td>\n",
       "      <td>北京</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>北京</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>北京市</td>\n",
       "      <td>Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200</td>\n",
       "      <td>1201</td>\n",
       "      <td>天津</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>天津</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>天津市</td>\n",
       "      <td>Tianjin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201</td>\n",
       "      <td>1201</td>\n",
       "      <td>天津</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>天津</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>天津市</td>\n",
       "      <td>Tianjin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1202</td>\n",
       "      <td>1201</td>\n",
       "      <td>天津</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>天津</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>天津市</td>\n",
       "      <td>Tianjin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1301</td>\n",
       "      <td>1301</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>石家庄</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1302</td>\n",
       "      <td>1302</td>\n",
       "      <td>唐山</td>\n",
       "      <td>Tangshan</td>\n",
       "      <td>唐山</td>\n",
       "      <td>Tangshan</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1303</td>\n",
       "      <td>1303</td>\n",
       "      <td>秦皇岛</td>\n",
       "      <td>Qinhuangdao</td>\n",
       "      <td>秦皇岛</td>\n",
       "      <td>Qinhuangdao</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1304</td>\n",
       "      <td>1304</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>Handan</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>Handan</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   extra_code  geocode4_corr citycn        cityen citycn_correct  \\\n",
       "0        1100           1101     北京       Beijing             北京   \n",
       "1        1101           1101     北京       Beijing             北京   \n",
       "2        1102           1101     北京       Beijing             北京   \n",
       "3        1200           1201     天津       Tianjin             天津   \n",
       "4        1201           1201     天津       Tianjin             天津   \n",
       "5        1202           1201     天津       Tianjin             天津   \n",
       "6        1301           1301    石家庄  Shijiazhuang            石家庄   \n",
       "7        1302           1302     唐山      Tangshan             唐山   \n",
       "8        1303           1303    秦皇岛   Qinhuangdao            秦皇岛   \n",
       "9        1304           1304     邯郸        Handan             邯郸   \n",
       "\n",
       "  cityen_correct province_cn province_en  \n",
       "0        Beijing         北京市     Beijing  \n",
       "1        Beijing         北京市     Beijing  \n",
       "2        Beijing         北京市     Beijing  \n",
       "3        Tianjin         天津市     Tianjin  \n",
       "4        Tianjin         天津市     Tianjin  \n",
       "5        Tianjin         天津市     Tianjin  \n",
       "6   Shijiazhuang         河北省      Hebei   \n",
       "7       Tangshan         河北省      Hebei   \n",
       "8    Qinhuangdao         河北省      Hebei   \n",
       "9         Handan         河北省      Hebei   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT *\n",
    "FROM chinese_lookup.china_city_code_normalised\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_5'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Processing of Food from Agricultural Products</td>\n",
       "      <td>Processing foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>Foods</td>\n",
       "      <td>Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Tobacco</td>\n",
       "      <td>Tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Textile</td>\n",
       "      <td>Textile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Textile Wearing Apparel</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Leather</td>\n",
       "      <td>Fur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Processing of Timber</td>\n",
       "      <td>Manufacture of Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>Paper and Paper Products</td>\n",
       "      <td>Paper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic                                  industry_name                 short\n",
       "0   13  Processing of Food from Agricultural Products      Processing foods\n",
       "1   14                                          Foods                 Foods\n",
       "2   15                                      Beverages             Beverages\n",
       "3   16                                        Tobacco               Tobacco\n",
       "4   17                                        Textile               Textile\n",
       "5   18                       \"Textile Wearing Apparel              Footwear\n",
       "6   19                                       \"Leather                   Fur\n",
       "7   20                          \"Processing of Timber   Manufacture of Wood\n",
       "8   21                                      Furniture             Furniture\n",
       "9   22                       Paper and Paper Products                 Paper"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"\"\"\n",
    "SELECT *\n",
    "FROM chinese_lookup.ind_cic_2_name\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_6'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test merge on `china_city_reduction_mandate` and `china_city_code_normalised`\n",
    "\n",
    "Shanghai for instance has more than 3 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citycn</th>\n",
       "      <th>cityen</th>\n",
       "      <th>extra_code</th>\n",
       "      <th>geocode4_corr</th>\n",
       "      <th>tso2_mandate_c</th>\n",
       "      <th>in_10_000_tonnes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上海</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>3102</td>\n",
       "      <td>3101</td>\n",
       "      <td>1.327908</td>\n",
       "      <td>1.327908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>上海</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>3101</td>\n",
       "      <td>3101</td>\n",
       "      <td>1.327908</td>\n",
       "      <td>1.327908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上海</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>3100</td>\n",
       "      <td>3101</td>\n",
       "      <td>1.327908</td>\n",
       "      <td>1.327908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>昆明</td>\n",
       "      <td>Kunming</td>\n",
       "      <td>5301</td>\n",
       "      <td>5301</td>\n",
       "      <td>0.090013</td>\n",
       "      <td>0.900126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>曲靖</td>\n",
       "      <td>Qujing</td>\n",
       "      <td>5303</td>\n",
       "      <td>5303</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.492288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>玉溪</td>\n",
       "      <td>Yuxi</td>\n",
       "      <td>5304</td>\n",
       "      <td>5304</td>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.310153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>思茅</td>\n",
       "      <td>Simao</td>\n",
       "      <td>5308</td>\n",
       "      <td>5308</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.100333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>保山</td>\n",
       "      <td>Baoshan</td>\n",
       "      <td>5312</td>\n",
       "      <td>5305</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.090756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>保山</td>\n",
       "      <td>Baoshan</td>\n",
       "      <td>5305</td>\n",
       "      <td>5305</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.090756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>昭通</td>\n",
       "      <td>Zhaotong</td>\n",
       "      <td>5306</td>\n",
       "      <td>5306</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.069540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  citycn    cityen  extra_code  geocode4_corr  tso2_mandate_c  \\\n",
       "0     上海  Shanghai        3102           3101        1.327908   \n",
       "1     上海  Shanghai        3101           3101        1.327908   \n",
       "2     上海  Shanghai        3100           3101        1.327908   \n",
       "3     昆明   Kunming        5301           5301        0.090013   \n",
       "4     曲靖    Qujing        5303           5303        0.049229   \n",
       "5     玉溪      Yuxi        5304           5304        0.031015   \n",
       "6     思茅     Simao        5308           5308        0.010033   \n",
       "7     保山   Baoshan        5312           5305        0.009076   \n",
       "8     保山   Baoshan        5305           5305        0.009076   \n",
       "9     昭通  Zhaotong        5306           5306        0.006954   \n",
       "\n",
       "   in_10_000_tonnes  \n",
       "0          1.327908  \n",
       "1          1.327908  \n",
       "2          1.327908  \n",
       "3          0.900126  \n",
       "4          0.492288  \n",
       "5          0.310153  \n",
       "6          0.100333  \n",
       "7          0.090756  \n",
       "8          0.090756  \n",
       "9          0.069540  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT china_city_code_normalised.citycn, china_city_code_normalised.cityen, extra_code, geocode4_corr, tso2_mandate_c, in_10_000_tonnes\n",
    "FROM policy.china_city_reduction_mandate\n",
    "INNER JOIN chinese_lookup.china_city_code_normalised \n",
    "ON china_city_reduction_mandate.citycn = china_city_code_normalised.citycn\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_7'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the table with many city code\n",
    "\n",
    "A city can have more than one codes over time. Below, we show which tables have more than one code so we know on which columns we need to merge `extra_code` or `geocode4_corr` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**china_city_sector_pollution**\n",
    "\n",
    "The table `china_city_sector_pollution` needs to be matched using `extra_code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citycode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citycode\n",
       "0      3102\n",
       "1      3101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT(citycode)\n",
    "FROM environment.china_city_sector_pollution\n",
    "WHERE citycode in ('3100','3101','3102')\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_8'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**asif_city_industry_financial_ratio**\n",
    "\n",
    "The table `asif_city_industry_financial_ratio` needs to be matched using `extra_code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citycode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citycode\n",
       "0      3102\n",
       "1      3101\n",
       "2      3100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT(citycode)\n",
    "FROM firms_survey.asif_city_industry_financial_ratio\n",
    "WHERE citycode in ('3100','3101','3102')\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_8'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**china_city_tcz_spz**\n",
    "\n",
    "The table `china_city_tcz_spz` needs to be matched using `geocode4_corr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geocode4_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geocode4_corr\n",
       "0           3101"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT(geocode4_corr)\n",
    "FROM policy.china_city_tcz_spz\n",
    "WHERE geocode4_corr in ('3100','3101','3102')\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_8'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test merge\n",
    "\n",
    "Let's test the merge with the tables on `citycode` :\n",
    "\n",
    "- china_city_sector_pollution\n",
    "    - asif_city_industry_financial_ratio\n",
    "\n",
    "to be sure there is no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "      <th>dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT     dup\n",
       "0    1  126942"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH merge AS (\n",
    "SELECT asif_city_industry_financial_ratio.year, asif_city_industry_financial_ratio.citycode, cic, ind2, tso2, lower_location, larger_location, coastal\n",
    "FROM environment.china_city_sector_pollution\n",
    "INNER JOIN firms_survey.asif_city_industry_financial_ratio\n",
    "ON \n",
    "china_city_sector_pollution.citycode  = asif_city_industry_financial_ratio.citycode AND\n",
    "china_city_sector_pollution.year  = asif_city_industry_financial_ratio.year AND\n",
    "china_city_sector_pollution.indus_code  = asif_city_industry_financial_ratio.cic \n",
    "WHERE year in ('2001','2002', '2003', '2004', '2005', '2006', '2007')\n",
    ")\n",
    "\n",
    "SELECT CNT, COUNT(CNT) AS dup\n",
    "FROM (\n",
    "  SELECT citycode, year, cic, COUNT(*) AS CNT\n",
    "  FROM merge\n",
    "GROUP BY citycode, year, cic\n",
    "  ) AS count_dup\n",
    "GROUP BY CNT\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_9'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test by adding the  `china_city_reduction_mandate` and `china_city_code_normalised`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "      <th>dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT     dup\n",
       "0    1  126942"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH merge AS (\n",
    "SELECT asif_city_industry_financial_ratio.year, asif_city_industry_financial_ratio.citycode, cic, ind2, tso2,tso2_mandate_c,in_10_000_tonnes,lower_location, larger_location, coastal\n",
    "FROM environment.china_city_sector_pollution\n",
    "INNER JOIN firms_survey.asif_city_industry_financial_ratio\n",
    "ON \n",
    "china_city_sector_pollution.citycode  = asif_city_industry_financial_ratio.citycode AND\n",
    "china_city_sector_pollution.year  = asif_city_industry_financial_ratio.year AND\n",
    "china_city_sector_pollution.indus_code  = asif_city_industry_financial_ratio.cic \n",
    "INNER JOIN (\n",
    "  \n",
    "  SELECT china_city_code_normalised.citycn, china_city_code_normalised.cityen, extra_code, geocode4_corr, tso2_mandate_c, in_10_000_tonnes\n",
    "FROM policy.china_city_reduction_mandate\n",
    "INNER JOIN chinese_lookup.china_city_code_normalised \n",
    "ON china_city_reduction_mandate.citycn = china_city_code_normalised.citycn\n",
    ") as city_mandate\n",
    "  ON china_city_sector_pollution.citycode  = city_mandate.extra_code\n",
    "\n",
    "WHERE year in ('2001','2002', '2003', '2004', '2005', '2006', '2007')\n",
    ")\n",
    "\n",
    "SELECT CNT, COUNT(CNT) AS dup\n",
    "FROM (\n",
    "  SELECT citycode, year, cic, COUNT(*) AS CNT\n",
    "  FROM merge\n",
    "GROUP BY citycode, year, cic\n",
    "  ) AS count_dup\n",
    "GROUP BY CNT\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_9'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test by adding `china_city_tcz_spz` on `geocode4_corr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "      <th>dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT     dup\n",
       "0    1  126942"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH merge AS (\n",
    "SELECT asif_city_industry_financial_ratio.year, asif_city_industry_financial_ratio.citycode,tcz, spz, cic, ind2, tso2,tso2_mandate_c,in_10_000_tonnes,lower_location, larger_location, coastal\n",
    "FROM environment.china_city_sector_pollution\n",
    "INNER JOIN firms_survey.asif_city_industry_financial_ratio\n",
    "ON \n",
    "china_city_sector_pollution.citycode  = asif_city_industry_financial_ratio.citycode AND\n",
    "china_city_sector_pollution.year  = asif_city_industry_financial_ratio.year AND\n",
    "china_city_sector_pollution.indus_code  = asif_city_industry_financial_ratio.cic \n",
    "INNER JOIN (\n",
    "  \n",
    "  SELECT china_city_code_normalised.citycn, china_city_code_normalised.cityen, extra_code, geocode4_corr, tso2_mandate_c, in_10_000_tonnes\n",
    "FROM policy.china_city_reduction_mandate\n",
    "INNER JOIN chinese_lookup.china_city_code_normalised \n",
    "ON china_city_reduction_mandate.citycn = china_city_code_normalised.citycn\n",
    ") as city_mandate\n",
    "  ON china_city_sector_pollution.citycode  = city_mandate.extra_code\n",
    "\n",
    "LEFT JOIN policy.china_city_tcz_spz\n",
    "  ON china_city_sector_pollution.citycode  = china_city_tcz_spz.geocode4_corr\n",
    "WHERE year in ('2001','2002', '2003', '2004', '2005', '2006', '2007')\n",
    ")\n",
    "\n",
    "SELECT CNT, COUNT(CNT) AS dup\n",
    "FROM (\n",
    "  SELECT citycode, year, cic, COUNT(*) AS CNT\n",
    "  FROM merge\n",
    "GROUP BY citycode, year, cic\n",
    "  ) AS count_dup\n",
    "GROUP BY CNT\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'example_9'\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table `fin_dep_pollution_baseline`\n",
    "\n",
    "Since the table to create has missing value, please use the following at the top of the query\n",
    "\n",
    "```\n",
    "CREATE TABLE database.table_name WITH (format = 'PARQUET') AS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a location in S3 to save the CSV. It is recommended to save in it the `datalake-datascience` bucket. Locate an appropriate folder in the bucket, and make sure all output have the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'DATA/ENVIRONMENT/CHINA/FYP/FINANCIAL_CONTRAINT/PAPER_FYP_FINANCE_POL/BASELINE'\n",
    "table_name = 'fin_dep_pollution_baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to delete the table (if exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = glue.delete_table(\n",
    "        database=DatabaseName,\n",
    "        table=table_name\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the folder with the previous csv file. Be careful, it will erase all files inside the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.remove_all_bucket(path_remove = s3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "  asif_city_industry_financial_ratio.year, \n",
    "  CASE WHEN asif_city_industry_financial_ratio.year in (\n",
    "    '2001', '2002', '2003', '2004', '2005'\n",
    "  ) THEN 'FALSE' WHEN asif_city_industry_financial_ratio.year in ('2006', '2007') THEN 'TRUE' END AS period, \n",
    "  provinces, \n",
    "  china_city_sector_pollution.cityen, \n",
    "  asif_city_industry_financial_ratio.citycode, \n",
    "  tcz, \n",
    "  spz, \n",
    "  asif_city_industry_financial_ratio.cic, \n",
    "  ind2, \n",
    "  short, \n",
    "  tso2, \n",
    "  tso2_mandate_c, \n",
    "  in_10_000_tonnes, \n",
    "  working_capital_cit, \n",
    "  working_capital_ci, \n",
    "  working_capital_i, \n",
    "  asset_tangibility_cit, \n",
    "  asset_tangibility_ci, \n",
    "  asset_tangibility_i, \n",
    "  current_ratio_cit, \n",
    "  current_ratio_ci, \n",
    "  current_ratio_i, \n",
    "  cash_assets_cit, \n",
    "  cash_assets_ci, \n",
    "  cash_assets_i, \n",
    "  liabilities_assets_cit, \n",
    "  liabilities_assets_ci, \n",
    "  liabilities_assets_i, \n",
    "  return_on_asset_cit, \n",
    "  return_on_asset_ci, \n",
    "  return_on_asset_i, \n",
    "  sales_assets_cit, \n",
    "  sales_assets_ci, \n",
    "  sales_assets_i, \n",
    "  lower_location, \n",
    "  larger_location, \n",
    "  coastal \n",
    "FROM \n",
    "  environment.china_city_sector_pollution \n",
    "  INNER JOIN firms_survey.asif_city_industry_financial_ratio ON china_city_sector_pollution.citycode = asif_city_industry_financial_ratio.citycode \n",
    "  AND china_city_sector_pollution.year = asif_city_industry_financial_ratio.year \n",
    "  AND china_city_sector_pollution.indus_code = asif_city_industry_financial_ratio.cic \n",
    "  INNER JOIN (\n",
    "    SELECT \n",
    "      china_city_code_normalised.citycn, \n",
    "      china_city_code_normalised.cityen, \n",
    "      extra_code, \n",
    "      geocode4_corr, \n",
    "      tso2_mandate_c, \n",
    "      in_10_000_tonnes \n",
    "    FROM \n",
    "      policy.china_city_reduction_mandate \n",
    "      INNER JOIN chinese_lookup.china_city_code_normalised ON china_city_reduction_mandate.citycn = china_city_code_normalised.citycn\n",
    "  ) as city_mandate ON china_city_sector_pollution.citycode = city_mandate.extra_code \n",
    "  LEFT JOIN policy.china_city_tcz_spz ON china_city_sector_pollution.citycode = china_city_tcz_spz.geocode4_corr \n",
    "  LEFT JOIN chinese_lookup.ind_cic_2_name ON china_city_sector_pollution.ind2 = ind_cic_2_name.cic \n",
    "WHERE \n",
    "  asif_city_industry_financial_ratio.year in (\n",
    "    '2001', '2002', '2003', '2004', '2005', \n",
    "    '2006', '2007'\n",
    "  ) \n",
    "LIMIT \n",
    "  10\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".format(DatabaseName, table_name)\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output,\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*) AS CNT\n",
    "FROM {}.{} \n",
    "\"\"\".format(DatabaseName, table_name)\n",
    "output = s3.run_query(\n",
    "                    query=query,\n",
    "                    database=DatabaseName,\n",
    "                    s3_output=s3_output_example,\n",
    "    filename = 'count_{}'.format(table_name)\n",
    "                )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate query\n",
    "\n",
    "This step is mandatory to validate the query in the ETL. If you are not sure about the quality of the query, go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the query, please fillin the json below. Don't forget to change the schema so that the crawler can use it.\n",
    "\n",
    "1. Add a partition key:\n",
    "    - Inform if there is group in the table so that, the parser can compute duplicate\n",
    "2. Add the steps number -> Not automtic yet. Start at 0\n",
    "3. Change the schema if needed. It is highly recommanded to add comment to the fields\n",
    "4. Provide a description -> detail the steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add a partition key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_keys = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add the steps number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Change the schema\n",
    "\n",
    "Bear in mind that CSV SerDe (OpenCSVSerDe) does not support empty fields in columns defined as a numeric data type. All columns with missing values should be saved as string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue.get_table_information(\n",
    "    database = DatabaseName,\n",
    "    table = table_name)['Table']['StorageDescriptor']['Columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\n",
    "    {\n",
    "        \"Name\": \"VAR1\",\n",
    "        \"Type\": \"\",\n",
    "        \"Comment\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"VAR2\",\n",
    "        \"Type\": \"\",\n",
    "        \"Comment\": \"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Provide a description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. provide metadata\n",
    "\n",
    "- DatabaseName\n",
    "- TablePrefix\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_etl = {\n",
    "    'step': 1,\n",
    "    'description':description,\n",
    "    'query':query,\n",
    "    'schema': schema,\n",
    "    'partition_keys':partition_keys,\n",
    "    'metadata':{\n",
    "    'DatabaseName' : DatabaseName,\n",
    "    'TableName' : table_name,\n",
    "    'target_S3URI' : os.path.join('s3://',bucket, s3_output),\n",
    "    'from_athena': 'True'    \n",
    "    }\n",
    "}\n",
    "json_etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(str(Path(path).parent), 'parameters_ETL_TEMPLATE.json')) as json_file:\n",
    "    parameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the step number from the current file (if exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = next(\n",
    "                (\n",
    "                    index\n",
    "                    for (index, d) in enumerate(parameters['TABLES']['PREPARATION']['STEPS'])\n",
    "                    if d[\"step\"] == step\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "if index_to_remove != None:\n",
    "    parameters['TABLES']['PREPARATION']['STEPS'].pop(index_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['TABLES']['PREPARATION']['STEPS'].append(json_etl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(str(Path(path).parent), 'parameters_ETL_TEMPLATE.json'), \"w\")as outfile:\n",
    "    json.dump(parameters, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create or update the data catalog\n",
    "\n",
    "The query is saved in the S3 (bucket `datalake-datascience`) but the table is not available yet in the Data Catalog. Use the function `create_table_glue` to generate the table and update the catalog.\n",
    "\n",
    "Few parameters are required:\n",
    "\n",
    "- name_crawler: Name of the crawler\n",
    "- Role: Role to temporary provide an access tho the service\n",
    "- DatabaseName: Name of the database to create the table\n",
    "- TablePrefix: Prefix of the table. Full name of the table will be `TablePrefix` + folder name\n",
    "\n",
    "To update the schema, please use the following structure\n",
    "\n",
    "```\n",
    "schema = [\n",
    "    {\n",
    "        \"Name\": \"VAR1\",\n",
    "        \"Type\": \"\",\n",
    "        \"Comment\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"VAR2\",\n",
    "        \"Type\": \"\",\n",
    "        \"Comment\": \"\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue.update_schema_table(\n",
    "    database = DatabaseName,\n",
    "    table = table_name,\n",
    "    schema= schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Duplicates\n",
    "\n",
    "One of the most important step when creating a table is to check if the table contains duplicates. The cell below checks if the table generated before is empty of duplicates. The code uses the JSON file to create the query parsed in Athena. \n",
    "\n",
    "You are required to define the group(s) that Athena will use to compute the duplicate. For instance, your table can be grouped by COL1 and COL2 (need to be string or varchar), then pass the list ['COL1', 'COL2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_keys = []\n",
    "\n",
    "with open(os.path.join(str(Path(path).parent), 'parameters_ETL_TEMPLATE.json')) as json_file:\n",
    "    parameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNT DUPLICATES\n",
    "if len(partition_keys) > 0:\n",
    "    groups = ' , '.join(partition_keys)\n",
    "\n",
    "    query_duplicates = parameters[\"ANALYSIS\"]['COUNT_DUPLICATES']['query'].format(\n",
    "                                DatabaseName,table_name,groups\n",
    "                                )\n",
    "    dup = s3.run_query(\n",
    "                                query=query_duplicates,\n",
    "                                database=DatabaseName,\n",
    "                                s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "                                filename=\"duplicates_{}\".format(table_name))\n",
    "    display(dup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics\n",
    "\n",
    "In this part, we are providing basic summary statistic. Since we have created the tables, we can parse the schema in Glue and use our json file to automatically generates the analysis.\n",
    "\n",
    "The cells below execute the job in the key `ANALYSIS`. You need to change the `primary_key` and `secondary_key` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full analysis of the table, please use the following Lambda function. Be patient, it can takes between 5 to 30 minutes. Times varies according to the number of columns in your dataset.\n",
    "\n",
    "Use the function as follow:\n",
    "\n",
    "- `output_prefix`:  s3://datalake-datascience/ANALYTICS/OUTPUT/TABLE_NAME/\n",
    "- `region`: region where the table is stored\n",
    "- `bucket`: Name of the bucket\n",
    "- `DatabaseName`: Name of the database\n",
    "- `table_name`: Name of the table\n",
    "- `group`: variables name to group to count the duplicates\n",
    "- `primary_key`: Variable name to perform the grouping -> Only one variable for now\n",
    "- `secondary_key`: Variable name to perform the secondary grouping -> Only one variable for now\n",
    "- `proba`: Chi-square analysis probabilitity\n",
    "- `y_var`: Continuous target variables\n",
    "\n",
    "Check the job processing in Sagemaker: https://eu-west-3.console.aws.amazon.com/sagemaker/home?region=eu-west-3#/processing-jobs\n",
    "\n",
    "The notebook is available: https://s3.console.aws.amazon.com/s3/buckets/datalake-datascience?region=eu-west-3&prefix=ANALYTICS/OUTPUT/&showversions=false\n",
    "\n",
    "Please, download the notebook on your local machine, and convert it to HTML:\n",
    "\n",
    "```\n",
    "cd \"/Users/thomas/Downloads/Notebook\"\n",
    "aws s3 cp s3://datalake-datascience/ANALYTICS/OUTPUT/asif_unzip_data_csv/Template_analysis_from_lambda-2020-11-22-08-12-20.ipynb .\n",
    "\n",
    "## convert HTML no code\n",
    "jupyter nbconvert --no-input --to html Template_analysis_from_lambda-2020-11-21-14-30-45.ipynb\n",
    "jupyter nbconvert --to html Template_analysis_from_lambda-2020-11-22-08-12-20.ipynb\n",
    "```\n",
    "\n",
    "Then upload the HTML to: https://s3.console.aws.amazon.com/s3/buckets/datalake-datascience?region=eu-west-3&prefix=ANALYTICS/HTML_OUTPUT/\n",
    "\n",
    "Add a new folder with the table name in upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "key, secret_ = con.load_credential()\n",
    "client_lambda = boto3.client(\n",
    "    'lambda',\n",
    "    aws_access_key_id=key,\n",
    "    aws_secret_access_key=secret_,\n",
    "    region_name = region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = ''\n",
    "secondary_key = ''\n",
    "y_var = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"input_path\": \"s3://datalake-datascience/ANALYTICS/TEMPLATE_NOTEBOOKS/template_analysis_from_lambda.ipynb\",\n",
    "    \"output_prefix\": \"s3://datalake-datascience/ANALYTICS/OUTPUT/{}/\".format(table_name.upper()),\n",
    "    \"parameters\": {\n",
    "        \"region\": \"{}\".format(region),\n",
    "        \"bucket\": \"{}\".format(bucket),\n",
    "        \"DatabaseName\": \"{}\".format(DatabaseName),\n",
    "        \"table_name\": \"{}\".format(table_name),\n",
    "        \"group\": \"{}\".format(','.join(partition_keys)),\n",
    "        \"keys\": \"{},{}\".format(primary_key,secondary_key),\n",
    "        \"y_var\": \"{}\".format(y_var),\n",
    "        \"threshold\":0\n",
    "    },\n",
    "}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client_lambda.invoke(\n",
    "    FunctionName='RunNotebook',\n",
    "    InvocationType='RequestResponse',\n",
    "    LogType='Tail',\n",
    "    Payload=json.dumps(payload),\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a partial analysis, run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = 'XX'\n",
    "schema = glue.get_table_information(\n",
    "    database = DatabaseName,\n",
    "    table = table_name\n",
    ")['Table']\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today().strftime('%Y%M%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_top = parameters[\"ANALYSIS\"][\"COUNT_MISSING\"][\"top\"]\n",
    "table_middle = \"\"\n",
    "table_bottom = parameters[\"ANALYSIS\"][\"COUNT_MISSING\"][\"bottom\"].format(\n",
    "    DatabaseName, table_name\n",
    ")\n",
    "\n",
    "for key, value in enumerate(schema[\"StorageDescriptor\"][\"Columns\"]):\n",
    "    if key == len(schema[\"StorageDescriptor\"][\"Columns\"]) - 1:\n",
    "\n",
    "        table_middle += \"{} \".format(\n",
    "            parameters[\"ANALYSIS\"][\"COUNT_MISSING\"][\"middle\"].format(value[\"Name\"])\n",
    "        )\n",
    "    else:\n",
    "        table_middle += \"{} ,\".format(\n",
    "            parameters[\"ANALYSIS\"][\"COUNT_MISSING\"][\"middle\"].format(value[\"Name\"])\n",
    "        )\n",
    "query = table_top + table_middle + table_bottom\n",
    "output = s3.run_query(\n",
    "    query=query,\n",
    "    database=DatabaseName,\n",
    "    s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "    filename=\"count_missing\",  ## Add filename to print dataframe\n",
    "    destination_key=None,  ### Add destination key if need to copy output\n",
    ")\n",
    "display(\n",
    "    output.T.rename(columns={0: \"total_missing\"})\n",
    "    .assign(total_missing_pct=lambda x: x[\"total_missing\"] / x.iloc[0, 0])\n",
    "    .sort_values(by=[\"total_missing\"], ascending=False)\n",
    "    .style.format(\"{0:,.2%}\", subset=[\"total_missing_pct\"])\n",
    "    .bar(subset=\"total_missing_pct\", color=[\"#d65f5f\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief description table\n",
    "\n",
    "In this part, we provide a brief summary statistic from the lattest jobs. For the continuous analysis with a primary/secondary key, please add the relevant variables you want to know the count and distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Description\n",
    "\n",
    "During the categorical analysis, we wil count the number of observations for a given group and for a pair.\n",
    "\n",
    "### Count obs by group\n",
    "\n",
    "- Index: primary group\n",
    "- nb_obs: Number of observations per primary group value\n",
    "- percentage: Percentage of observation per primary group value over the total number of observations\n",
    "\n",
    "Returns the top 10 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in schema[\"StorageDescriptor\"][\"Columns\"]:\n",
    "    if field[\"Type\"] in [\"string\", \"object\", \"varchar(12)\"]:\n",
    "\n",
    "        print(\"Nb of obs for {}\".format(field[\"Name\"]))\n",
    "\n",
    "        query = parameters[\"ANALYSIS\"][\"CATEGORICAL\"][\"PAIR\"].format(\n",
    "            DatabaseName, table_name, field[\"Name\"]\n",
    "        )\n",
    "        output = s3.run_query(\n",
    "            query=query,\n",
    "            database=DatabaseName,\n",
    "            s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "            filename=\"count_categorical_{}\".format(\n",
    "                field[\"Name\"]\n",
    "            ),  ## Add filename to print dataframe\n",
    "            destination_key=None,  ### Add destination key if need to copy output\n",
    "        )\n",
    "\n",
    "        ### Print top 10\n",
    "\n",
    "        display(\n",
    "            (\n",
    "                output.set_index([field[\"Name\"]])\n",
    "                .assign(percentage=lambda x: x[\"nb_obs\"] / x[\"nb_obs\"].sum())\n",
    "                .sort_values(\"percentage\", ascending=False)\n",
    "                .head(10)\n",
    "                .style.format(\"{0:.2%}\", subset=[\"percentage\"])\n",
    "                .bar(subset=[\"percentage\"], color=\"#d65f5f\")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous description\n",
    "\n",
    "There are three possibilities to show the ditribution of a continuous variables:\n",
    "\n",
    "1. Display the percentile\n",
    "2. Display the percentile, with one primary key\n",
    "3. Display the percentile, with one primary key, and a secondary key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Display the percentile\n",
    "\n",
    "- pct: Percentile [.25, .50, .75, .95, .90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_top = \"\"\n",
    "table_top_var = \"\"\n",
    "table_middle = \"\"\n",
    "table_bottom = \"\"\n",
    "\n",
    "var_index = 0\n",
    "size_continuous = len([len(x) for x in schema[\"StorageDescriptor\"][\"Columns\"] if \n",
    "                       x['Type'] in [\"float\", \"double\", \"bigint\", 'int']])\n",
    "cont = 0\n",
    "for key, value in enumerate(schema[\"StorageDescriptor\"][\"Columns\"]):\n",
    "    if value[\"Type\"] in [\"float\", \"double\", \"bigint\", 'int']:\n",
    "        cont +=1\n",
    "\n",
    "        if var_index == 0:\n",
    "            table_top_var += \"{} ,\".format(value[\"Name\"])\n",
    "            table_top = parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\n",
    "                \"bottom\"\n",
    "            ].format(DatabaseName, table_name, value[\"Name\"], key)\n",
    "        else:\n",
    "            temp_middle_1 = \"{} {}\".format(\n",
    "                parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\"middle_1\"],\n",
    "                parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\"bottom\"].format(\n",
    "                    DatabaseName, table_name, value[\"Name\"], key\n",
    "                ),\n",
    "            )\n",
    "            temp_middle_2 = parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\n",
    "                \"middle_2\"\n",
    "            ].format(value[\"Name\"])\n",
    "\n",
    "            if cont == size_continuous:\n",
    "\n",
    "                table_top_var += \"{} {}\".format(\n",
    "                    value[\"Name\"],\n",
    "                    parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\"top_3\"],\n",
    "                )\n",
    "                table_bottom += \"{} {})\".format(temp_middle_1, temp_middle_2)\n",
    "            else:\n",
    "                table_top_var += \"{} ,\".format(value[\"Name\"])\n",
    "                table_bottom += \"{} {}\".format(temp_middle_1, temp_middle_2)\n",
    "        var_index += 1\n",
    "\n",
    "query = (\n",
    "    parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\"top_1\"]\n",
    "    + table_top\n",
    "    + parameters[\"ANALYSIS\"][\"CONTINUOUS\"][\"DISTRIBUTION\"][\"top_2\"]\n",
    "    + table_top_var\n",
    "    + table_bottom\n",
    ")\n",
    "output = s3.run_query(\n",
    "    query=query,\n",
    "    database=DatabaseName,\n",
    "    s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "    filename=\"count_distribution\",  ## Add filename to print dataframe\n",
    "    destination_key=None,  ### Add destination key if need to copy output\n",
    ")\n",
    "\n",
    "display(output.sort_values(by=\"pct\").set_index([\"pct\"]).style.format(\"{0:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.22.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
